<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" type="text/css" href="../format.css">
</head>
<body>
    <h1>Aplicação de Redes Neurais Artificiais na Sugestão de Investimentos</h1>
    <h3>Lucas Flasch Romani</h3>
    <p>Monografia apresentada como requisito parcial para conclusão do Bacharelado em Ciência da Computação</p>
    <h3>Brasília - 2017</h3>
    <h1>Resumo</h1>
    <p>Este trabalho apresenta um meio de treinar uma Rede Neural Artificial para oferecimento de produtos de investimento que melhorem o rendimento de clientes, porém, mantendo-os adequados ao seu padrão de investimento. Através da utilização dos dados de clientes com a maior rentabilidade em suas carteiras de investimento e alinhados ao seu perfil de investidor, a rede é treinada. Cada aplicação feita pelos melhores clientes se torna a saída da rede neural, a carteia atual de produtos de cada cliente, assim como o perfil escolhido pelo mesmo, se tornam a entrada. Após o treinamento, a validade da rede é verificada para garantir que houve o aumento da rentabilidade na maioria dos casos. Dessa forma, clientes que estejam em situação semelhante, podem melhorar seus investimentos através de consulta à rede. Devido ao grande volume de dados, técnicas para otimizar a performance, como a utilização de placas de gráficas no processamento, foram utilizadas. Também foram observadas técnicas para a compensação do desbalanceamento dos dados, que resultaram na utilização de uma metodologia pouco ortodoxa, mas de grande efetividade, no tratamento desse desbalanceamento. Bibliotecas pré-formatadas para trabalho com redes neurais através da linguagem de programação Python também foram utilizadas, o que diminuiu o tempo de criação das redes. Melhorias futuras incluem evolução do algoritmo, testes com outros métodos de inteligência artificial e previsão de comportamento de mercado.</p>
    <h1>Capítulo 1</h1>
    <h1>Introdução</h1>
    <p>O mercado de investimentos é parte do sistema financeiro. Nele um agente superavitário empresta seu capital a um agente deficitário com o objetivo de compensação financeira. Este empréstimo ocorre através de uma instituição financeira, devidamente regularizada no sistema financeiro. Dessa forma, analogamente para o mercado de investimentos, um investidor empresta seu capital a outro agente com o objetivo de obter lucro. O investimento é visto como um produto, ofertado pela instituição financeira que intermediará a operação.</p>
    <p>Os investimentos sempre foram um desafio para o setor financeiro no que tange à oferta de produtos. Com uma grande variedade, cada um com vantagens e desvantagens, comparar todos os produtos e sugerir uma combinação que seja a melhor para o investidor é uma tarefa complexa. A complexidade envolvida se deve por diversos fatores, dentre eles a grande quantidade de produtos, a análise das condições econômicas, a análise das preferências de cada investidor, além das questões legais envolvidas.</p>
    <p>Dentre as instituições que regulam nacionalmente os investimentos, temos a Comissão de Valores Mobiliários (CVM). Conforme regulamentação da CVM de 2013, as instituições financeiras do Brasil tiveram de implementar mecanismos que garantissem a conformidade entre os interesses do cliente investidor, seus perfis de investimento e as aplicações que efetuassem. Estes mecanismos aumentaram a complexidade na sugestão de produtos de investimento. Agora, uma sugestão de aplicação deve melhorar a rentabilidade dos investimentos do cliente, estar em conformidade com os interesses do mesmo e com os dispositivos dessa regulamentação.</p>
    <p>A principal característica da regulamentação é normatizar o que muitas instituições já faziam de um modo menos formal. Tais instituições procuravam: alinhar o comportamento do cliente no que tange a sua capacidade de assumir riscos, seu conhecimento do cenário econômico e de investimentos, sua situação financeira e seus interesses em curto, médio e longo prazo. O resultados da análise dessas características é conhecido como perfil de investidor. Com o resultado da identificação do perfil do investidor é possível saber se os investimentos do mesmo estão enquadrados com esse perfil.</p>
    <h1>1.1 Problema</h1>
    <p>Dessa forma, este trabalho parte do seguinte problema de pesquisa: dado um conjunto de produtos de investimento, uma carteira de produtos que um cliente possui e uma regra de enquadramento que limite o tamanho das aplicações por risco de produto, encontrar, de maneira automática, um bom produto para ser sugerido como a próxima aplicação, aumentando os lucros da carteira sem afetar a regra de enquadramento.</p>
    <h1>1.2 Justificativa</h1>
    <p>A importância deste trabalho se reflete em melhorar as aplicações de investidores sem comprometer os risco do investimento sob o aspecto legal. Atualmente muitas instituições fazem a oferta de produtos de investimento conforme interesse negocial ou por simples adequação ao perfil. Dessa forma, raramente é ofertado um produto ao cliente que possui rentabilidade boa e adequação ao perfil.</p>
    <p>Como analista da área de tecnologia de um banco público, atuando na análise de sistemas de investimentos, identifiquei que esse problema é comum entre instituições financeiras e tem dificultado a relação entre cliente e banco, dado que as restrições impostas pela CVM não permitem a oferta de qualquer produto de investimento, ainda que melhore a rentabilidade do portfólio de aplicações do mesmo.</p>
    <h1>1.3 Hipótese</h1>
    <p>É possível encontrar uma boa aplicação para um determinado cliente através do uso de redes neurais, baseando-se na experiência de aplicações de clientes experientes e/ou bem sucedidos.</p>
    <h1>1.4 Objetivos</h1>
    <h1>1.4.1 Objetivo Geral</h1>
    <p>O objetivo geral desta pesquisa é propor e validar o uso de uma nova metodologia baseada em Redes Neurais na busca automática de boas ofertas de produtos de investimento personalizadas.</p>
    <h1>1.4.2 Objetivos Específicos</h1>
    <p>Para atingir o objetivo geral temos os seguintes objetivos específicos.</p>
    <ul>
        <li>Selecionar a partir dos bancos de dados disponíveis, dados reais de produtos e aplicações de clientes;</li>
        <li>Estudar a teoria na qual são baseadas as Redes Neurais;</li>
        <li>Propor e testar estruturas de Redes Neurais adequadas à solução do problema de pesquisa;</li>
        <li>Avaliar a eficiência da soluções encontradas na busca por investimentos mais rentáveis.</li>
    </ul>
    <h1>1.5 Organização</h1>
    <p>Este trabalho encontra-se assim organizado:</p>
    <p>Capítulo 2 - Revisão Teórica. Neste capítulo são abordados os conceitos fundamentais para a interpretação do trabalho: Análise do Perfil do Investidor, Análise de Conceitos de Rentabilidade, Técnicas de Inteligência Artificial e Mineração de Dados.</p>
    <p>Capítulo 3 - Sistema Proposto. Este capítulo descreve a obtenção e tratamento dos dados, assim como os experimentos realizados e os resultados obtidos com a aplicação das técnicas mencionadas no capítulo anterior.</p>
    <p>Capítulo 4 - Resultados Obtidos. Neste capítulo são comparados os resultados provenientes das técnicas utilizadas e é feita a análise de tais resultados.</p>
    <p>Capítulo 5 - Conclusão. Este capítulo sumariza a metodologia, os resultados e a análise, apresentado as conclusões obtidas.</p>
    <h1>Capítulo 3</h1>
    <h1>Sistema Proposto</h1>
    <p>Neste capítulo é descrita a metodologia proposta para a solução do problema de se encontrar um bom investimento conforme o perfil de investidor e sua carteira de investimentos, baseada em redes neurais artificiais. Inicialmente os dados disponíveis são descritos e a sua análise é realizada de modo a justificar as escolhas subsequentes.</p>
    <h1>3.1 Estrutura dos dados</h1>
    <p>A coleta de dados foi realizada em um banco público de projeção nacional, com uma base de mais de onze milhões de investidores, seis milhões, dos quais, são pessoas físicas. O sistema de origem dos dados é responsável pela aplicação do Análise de Perfil de Investidor (API). Por esse motivo possui os dados relevantes para criação da rede neural, como risco de produtos, saldo por produto do cliente, enquadramento, entre outros.</p>
    <p>Apenas as pessoas físicas que realizaram aplicações foram selecionadas para o treino e testes, uma vez que as pessoas jurídicas necessitem de uma análise mais detalhada devido a diversos fatores. Entre os fatores estão questões legais, pois são mais propensas a não participar do API, e questões de volume, pois possuem tendência a conseguir taxas diferenciadas nos investimentos devido ao volume de suas aplicações, o que invalida o objetivo deste trabalho.</p>
    <p>A fim de efetuar uma coleta representativa dos dados, foram considerados todos os investidores que realizaram aplicações em setembro de 2016.</p>
    <p>Os dados dos experimentos são obtidos das bases necessárias para a aplicação do processo API no banco em questão.</p>
    <h1>3.1.1 Questionários do Cliente</h1>
    <p>É uma exigência da legislação vigente que cada cliente investidor possua um ou mais questionários respondidos ou assine o termo de recusa de resposta. Dessa forma, o sistema só permite prosseguir com as aplicações caso o investidor tenha passado pelo processo API. Caso o cliente tenha optado por responder o questionário, o resultado das respostas será o perfil de investidor. Ou seja, lhe é atribuída de uma característica dentre: Conservador, Moderado, Arrojado ou Agressivo. Essa característica, também conhecida como perfil, orienta qual comportamento o investidor deve possuir na hora de investir.</p>
    <p>Cada questionário varia conforme o mercado em que o cliente se encontre. Clientes de mercados diferentes recebem questionários diferentes, porém todos medem o perfil de investidor ao final. O mercado revela qual o nível de entendimento do cliente sobre investimentos. Os clientes são segmentados através diversas características que indiquem qual seu nível de entendimento sobre investimentos, através de um processo automático do sistema. Portanto, quando um questionário é respondido, também é associado o mercado que o clientes se encontra ao questionário, por exemplo: se o cliente se encontra em um mercado “Varejo” ou “Alta Renda”. A combinação perfil e mercado dita quais devem ser as distribuições de risco dos produtos do investidor.</p>
    <p>Para fins legais, sempre deve ser considerado na análise do perfil e do mercado, o questionário mais recente do cliente. O que torna a data de preenchimento do questionário relevante para consolidação dos dados na entrada da rede.</p>
    <h1>3.1.2 Produtos do Cliente</h1>
    <p>Para verificação da conformidade dos investimentos do cliente ao seu perfil de investidor, é necessária a informação dos saldos dos produtos de investimento do mesmo, assim como na obtenção da rentabilidade da carteira. O sistema deve alertar se a próxima aplicação que será realizada está conforme com o perfil e mercado do cliente, o que implica no gerenciamento do risco dos produtos pelo próprio cliente. Outra informação importante obtida pelo saldo dos produtos do cliente é a rentabilidade da carteira. Essa informação deve ser considerada na distinção dos investidores que possuem rentabilidade acima da média, que é a entrada da rede neural.</p>
    <h1>3.1.3 Enquadramento do Cliente</h1>
    <p>Com base nas informações coletadas dos questionários e dos produtos dos clientes é possível identificar quais clientes estão aderentes ao seu perfil. Por exemplo: para um cliente que pertença ao mercado “Varejo” e possua um perfil de investidor “Conservador”, é permitido apenas dez porcento de seus investimentos em produtos de alto risco. Caso o cliente possua todos os seus investimentos em baixo risco, como poupança, o mesmo estará aderente. Se ele possuir até dez porcento de seus investimentos em alto risco, ainda se encontrará aderente. Porém se o cliente possuir todos os seus investimentos em alto risco, como ações, estará inaderente. A demonstração deste conceito pode ser visto na</p>
    <p>Considerando a regra de enquadramento anterior, é possível calcular quanto um cliente pode aplicar em determinado produto. Cada produto possui um risco associado, que, para que o cliente não fique desenquadrado, não deve ultrapassar o máximo permitido para o risco desse produto. Dessa forma é possível calcular o máximo aplicável antes do desenquadramento em um produto através da Equação 3.1 onde PM é o percentual máximo para o risco da aplicação, T O é o total investido pelo cliente, T R é o total que o cliente já possui alocado no mesmo risco do produto e V A é o valor da aplicação resultante.</p>
    <h1>3.1.4 Rentabilidade do Produto</h1>
    <p>Cada produto possui uma rentabilidade associada. O cálculo da rentabilidade é realizado subtraindo-se o valor final obtido de uma aplicação hipotética no produto há 365 dias. Em seguida, é dividido o resultado da subtração pelo valor aplicado inicialmente. Quando um produto não possui 365 dias de existência, é feita uma progressão geométrica levando em consideração os valores dos dias já conhecidos, projetando-se 365 dias à frente. Então é feito o cálculo anterior tendo como valor final o projetado.</p>
    <p>A rentabilidade dos produtos é utilizada na obtenção da rentabilidade da carteira. Cada produto da carteira de investimentos de um cliente tem sua rentabilidade multi plicada pelo percentual de sua participação na carteira. Em seguida são somados os resultados das multiplicações anteriores. O valor final é a rentabilidade da carteira.</p>
    <h1>3.1.5 Aplicações</h1>
    <p>Uma aplicação pode ser feita em qualquer produto de investimento, por qualquer cliente, a qualquer hora. Como cada aplicação realizada deve passar pelo processo API, a fim de conferir a aderência do cliente, o valor da aplicação é passado ao processo e gravado. Caso a aplicação que o cliente esteja prestes a fazer o desenquadre, o mesmo é alertado de sua condição. Apenas os clientes que realizaram aplicações são considerados na análise, uma vez que, a aplicação é a saída da rede proposta.</p>
    <h1>3.1.6 Metodologia</h1>
    <p>Para a montagem da entrada da rede são consideradas os clientes que realizaram aplicações no mês de setembro do 2016, cuja rentabilidade da carteira ficou acima da média e tenha permanecido enquadrados ao final da coleta. Para isso foram coletados os clientes que realizaram aplicações, desses clientes foi analisada a composição de cada carteira utilizando a regra de enquadramento. Dos que se encontravam na condição de enquadrados, a rentabilidade da carteira de cada cliente foi calculada. Foi feita a média das rentabilidades e foram selecionados os clientes cuja rentabilidade de sua carteira estava acima dessa média.</p>
    <p>Por fim, são geradas as entradas e saídas da rede neural. Cada aplicação realizada se torna uma coluna para a saída da rede. Cada produto da carteira do cliente se torna uma coluna de entrada seguido de outra coluna com o percentual carteira. Essas informações devem ser importantes na tomada de decisão da rede, que pode perceber nuances entre a relação de uma aplicação e de um percentual de determinado produto da carteira. O perfil do cliente se torna uma coluna de entrada, uma vez que há uma relação entre o código do perfil e o grau de risco que o cliente está disposto a tolerar. Cada tipo de mercado também se torna uma coluna, isso se deve por não haver uma relação direta entre o código do mercado e o nível de conhecimento sobre investimentos do cliente.</p>
    <h1>3.2 Distribuição dos dados</h1>
    <p>O período utilizado para a coleta dos dados corresponde às aplicações realizadas no mês de Setembro de 2016. A base de insumo das redes neurais possui as seguintes características:</p>
    <p>Vetores: O base possui 122496 (cento e vinte e dois mil quatrocentos e noventa e seis) vetores.</p>
    <p>Clientes: O número de clientes no arquivo de treino é de 113503 (cento e treze mil quinhentos e três). O número de clientes é menor do que o número de vetores devido a um cliente poder realizar mais de uma aplicação no mesmo mês. Ao contar o total de produtos e aplicações, obtemos 718 (setecentos e dezoito).</p>
    <p>Produtos Carteira: O total de produtos comercializados pelo banco é de 1322 (um mil trezentos e vinte e dois), porém os clientes considerados só possuíam 718 (setecentos e dezoito) desses produtos junto com as aplicações realizadas, dos quais 681 (seiscentos e oitenta e um) eram produtos de suas carteiras e 276 (duzentos e setenta e seis) eram aplicações. A distribuição dos produtos das carteiras na base de treino segue o gráfico Figura 3.2. Pode-se notar que a incidência de alguns produtos é maior do que outros. Essa diferença não deveria ser considerada na montagem da rede neural, pois pode tendenciar a rede a apresentar sempre os mesmos produtos. O que se quer é que ela apresente qualquer produto que maximize o rendimento sem perder o enquadra mento do cliente. Para isso é necessário que as aplicações tenham um volume de dados próximo, de modo que não se apresente sempre os mesmos produtos.</p>
    <p>Aplicações: Da mesma forma, é possível efetuar 718 aplicações diferentes, porém a quantidade de aplicações efetivas se concentra e 276 possibilidades.</p>
    <h1>3.3 Modelo Proposto</h1>
    <p>Como modelo de implementação proposta, a rede neural seria a parte intermediária de um sistema, que contemplaria uma camada de apresentação e busca ao banco de dados dos insumos necessários para a simulação da rede.</p>
    <p>A Figura 3.3 exemplifica a implementação do sistema. No caso, o cliente começa a interação se autenticando, acessa a área de investimentos, busca por uma sugestão de investimentos. O sistema obtém os insumos da rede, que são os investimentos atuais do cliente, bem como o perfil de investidor e o mercado que se encontra, então a rede simula as entradas e retorna a melhor aplicação para o cliente. Por fim o cliente realiza a aplicação proposta.</p>
    <p>Para futuras atualizações da RNA, seria incluída uma rotina de processamento de dados novos e os integraria à rede, através de trechos de código descritos posteriormente neste trabalho.</p>
    <h1>3.4 Implementações Propostas</h1>
    <p>O arquivo principal de treino foi processado através do código que segue. Para determinação de um bom ponto de eficiência, onde há maior ganho de tempo em relação a acurácia resultante, foram feitos testes com diversas configurações do código abaixo.</p>
    <h1>Exemplo de código 1:</h1>
    <p>Importação das bibliotecas: parte onde são importadas as bibliotecas do Theano, Time, Numpy e Keras. A biblioteca Theano possui os métodos para utilização otimizada de tabelas e para execução em placas de vídeo. A biblioteca Time possui os métodos de captura de tempo para o teste da performance. A biblioteca Numpy possui os métodos de criação de números e tratamento de tabelas otimizados para pesquisa científica. A biblioteca Keras possui as definições dos métodos para execução em alto nível de redes neurais (para que o Keras funcione é necessário a importação das bibliotecas Numpy e Theano). A biblioteca Matplotlib possui os métodos para visualização de gráficos em várias formas.</p>
    <p>Números randômicos: parte onde é declarado que as tabelas internas do Keras possuirão números randômicos gerados igualmente entre uma execução e outra. Dessa forma garante-se que se esteja comparando implementações iguais das redes neurais. No caso, o método que gera os números randômicos é o numpy.random.rand(x,y), utilizado pelo Keras para inicializar os neurônios e acrescentar ruído. Esse método alimenta uma tabela de x colunas e y linhas e funciona recursivamente, gerando números a partir da multiplicação da semente, definida em seed(7), por um número grande e retirando o módulo desse número. Como a semente é a mesma, sempre são gerados os mesmos números.</p>
    <p>Carregamento dos arquivos: a própria biblioteca Numpy possui métodos para carregamento de arquivos em diversos formatos como csv, txt, entre outros. O método utilizado carrega um arquivo texto de qualquer formato separado por vírgulas.</p>
    <p>Criação do modelo: parte onde são definidas as características do modelo a ser criado, camadas da rede, métodos intermediários como ruído, entre outros. No caso, é um modelo sequencial cujas camadas e propriedades vão sendo adicionadas em sequência. Cada camada pode conter neurônios ou funções que alimentam a rede ou evitam alguns comportamentos. Cada camada possui o seguinte comportamento:</p>
    <ul>
        <li>A primeira camada adicionada é uma rede neural com 1441 neurônios, cada neurônio representa uma coluna do arquivo de entrada. Não é necessário que a primeira camada tenha o mesmo número de neurônios que a quantidade de entrada, o que define a quantidade de entrada é o argumento input_dim que precisa ser especificado apenas no início, a partir disso as outras camadas já terão como padrão de entrada o número de saídas das camadas anteriores. A função de ativação utilizada nas camadas é a função sigmoide, outras funções também podem ser utilizadas. init= define de que forma serão atribuídos os pesos aleatórios iniciais nos neurônios daquela camada;</li>
        <li>A camada de Dropout é inserida com o objetivo de reduzir a probabilidade de overfitting, que é o especialização excessiva da rede. Ela altera a primeira camada de neurônios, funcionando como uma propriedade da mesma. Seu funcionamento se dá na retirada aleatória de alguns neurônios a cada passo de treino e finaliza uma rede diferente para cada batch. Ao final, na hora do teste, junta-se essas redes diferentes compondo uma única e fazendo a média dos pesos. Isso evita que surjam relações complexas na rede;</li>
        <li>A terceira camada possui 1080 neurônios, seguindo os padrões anteriores. Seus neurônios são automaticamente ligados com a saída da primeira camada;</li>
        <li>Outro Dropout é adicionado à terceira camada.</li>
        <li>Como saída é adicionada uma camada de 718 neurônios, que representam o total de aplicações possíveis.</li>
    </ul>
    <p>Início da contagem de tempo: parte onde se começa a contagem do tempo para aquisição dos dados de performance. Essa contagem começa antes do passo de compilação e treino. Isso se deve ao fato de que pode influenciar o tempo de compilação para placa de vídeo em relação ao tempo de compilação para o CPU. Se fosse considerado apenas o tempo de treino, o tempo de compilação poderia ter inviabilizado o tempo total, talvez fazendo com que a CPU fosse mais rápida.</p>
    <p>Compilação do modelo: a compilação montará o modelo, e carregará o métodos de execução na placa de vídeo se for utiliza essa modalidade. Ela começa com a definição de qual método de otimização será utilizado na rede. No caso, o método escolhido foi o Stochastic Gradient Descent (SGD). Este método busca o mínimo local da função de otimização após cada iteração. No código é definida a taxa de aprendizagem de 0.1 (lr=0.1), com taxa de decaimento da taxa de aprendizagem (decay=1e-6) de 0.000001, momento, que multiplica o vetor velocidade na direção do gradiente (momentum=0.9), é de 0.9 e utiliza o método de Nesterov (nesterov=True), que primeiro acumula o vetor de velocidade na direção do gradiente para depois corrigir esse vetor [41]. Uma vez montado o método de otimização, a compilação do modelo também precisa da definição da função de perda, no caso foi definida para múltiplas classes (loss=’categorical_crossentropy’). Essa definição é devida a natureza dos dados que possuem um vetor de valores binários e indicam qual aplicação foi realizada. Como última entrada para a compilação, mas sem a obrigatoriedade de defini-la, a medida de performance para o sistema adotada foi da acurácia ( metrics=[’accuracy’]), ou seja, número de predições corretas sobre todas as predições. Há outros métodos que podem minimizar os falsos positivos mesmo que sacrifiquem a precisão, mas a natureza desse problema não tem forte impacto nesse aspecto, uma vez que, mesmo que não se ofereça o melhor investimento, oferecer algum investimento bom já é o suficiente.</p>
    <p>Treino do modelo: nessa fase o modelo é treinado com os dados da fase de Carregamento dos arquivos (conjunto X e Y dos vetores de treino). No treinamento é definido o tamanho do batch, que é a quantidade de registros simulada para que haja uma atualização do gradiente. O batch escolhido foi 32 (batch_size=32), pois apresentou a melhor performance para o experimento. O batch influencia na performance, pois também é a taxa de carregamento da memória da placa de vídeo. Essa influência depende da arquitetura da máquina e tamanho do vetor simulado. Batches de tamanho grande também degradam o modelo, fazendo com que perca a capacidade de generalização. Foram testados batches de 4 até 512, acima disso a degradação é perceptível [42]. Defini-se época quando todos os registros foram usados para atualizar o modelo. No caso foram definidas 8 épocas (nb_epoch=8), pois apresentaram a melhor taxa de performance.</p>
    <p>Fim da contagem do tempo: finaliza-se a contagem antes da fase de avaliação, pois ela ocorre da mesma forma, mesmo que o treino tenha sido executado na placa de vídeo.</p>
    <p>Avaliação do modelo: são testados os mesmos vetores de entrada para verificação da acurácia total. Também pode ser utilizada para prever validar o modelo com um conjunto de testes ou verificar qual é o resultado da rede para uma entrada específica.</p>
    <p>Matriz de confusão: função onde se retorna a matriz de confusão para determinados dados e modelo. Essa função prediz qual o resultado da computação de uma entrada a partir da rede neural criada pelo comando model.predict(X). Em seguida cria a matriz de confusão com valores zerados. A função numpy.argmax retorna uma tabela com a posição do maior valor para cada linha (essa configuração é passada em axis=1, do contrário retornaria a maior posição da tabela inteira). Antes de retornar a matriz de confusão, alimenta cada célula que esteja com a posição do maior argumento previsto e do resultado real.</p>
    <p>Apresentação da matriz de confusão: área onde se transforma em escala logarítmica a matriz de confusão e apresenta o gráfico criado. Essa característica melhora a apresentação do gráfico, pois reduz a distância entre os resultados, facilitando para que dados que foram pouco testados também sejam apresentados, porém com coloração mais opaca.</p>
    <h1>3.4.1 Implementação com Múltiplos Tipos de Entrada</h1>
    <p>É possível através do Keras fazer a combinação de diferentes tipos de entrada em uma mesma rede neural desde que tenham a mesma saída. Essa metodologia é conhecida como Merge e pode ser utilizada para combinar entradas de texto com imagens, por exemplo, todas na mesma rede. Também pode ser utilizada para reduzir o grau de importância de uma determinada classificação que não se deseje enfatizar. Através do tratamento dos dados, separando a rede em duas, uma com todos os dados e outra retirando os dados relativos as classes que se deseje excluir, é possível diminuir o grau de influência dos dados menos desejados no resultado final. Essa técnica pode ser vista no exemplo de código:</p>
    <p>Exemplo de código 2:</p>
    <p>Separação dos dados: área onde se criará uma matriz de dados apartados, que possuam a característica de, quando aparecer a ocorrência do dado indesejado, se grave uma linha de registros vazios na matriz, para qualquer outro caso se grave a linha equivalente à matriz original. No caso, o registro menos desejado é da classificação três. Caso esse registro tenha muita influência sobre o conjunto de treino e isso não seja uma característica desejada, é recomendável que se diminua essa influência produzindo duas entradas, uma com ele e outra sem.</p>
    <p>Criação do modelo: nessa fase o modelo segue o exemplo de código anterior, porém cada modelo de entrada é integrado em um único modelo através da camada de Merge. No caso, o primeiro modelo é integrado com o segundo através da camada de Merge que faz parte do terceiro modelo.</p>
    <p>Compilação do modelo: essa fase segue a implementação do exemplo anterior, o modelo todo é visto como uma grande rede neural, por isso, mesmo que monte um modelo diferente, as métricas anteriores para a montagem desse modelo permanecem inalteradas.</p>
    <p>Treino do modelo: nessa fase que o treinamento se diferencias do exemplo anterior. Devem ser consideradas as duas entradas, uma para o primeiro modelo e outra para o segundo. Como os dados foram alterados, o primeiro e segundo modelos serão treinados diferentemente. Como o segundo modelo possui entradas zero para o treino da classificação três, seus pesos não são alterados para os registros dessa classificação, o que anula a importâncias desse registros nessa rede.</p>
    <h1>3.4.2 Implementação de Ponderação no Treino</h1>
    <p>O Keras permite associar aos vetores de entrada a ponderação na atualização de rede. Isso significa que um vetor pode ser mais ou menos importante na atualização dos pesos da rede conforme parâmetros passados na forma de array na entrada do treino (função fit no programa), onde os registros variam entre 0 e 1 para cada vetor. Essa técnica pode ser utilizada quando o conjunto de treino não reflete com exatidão as proporções do conjunto de teste ou há um desbalanceamento nos dados e pode ser vista no exemplo de código:</p>
    <p>Exemplo de código 3:</p>
    <p>No exemplo acima, é criado um array, através da função pesos, contendo os inversos da frequência de cada aplicação recebidos através do arquivo PESOAPLIC.TXT. Esse array será utilizado como peso associado a cada vetor durante o treino da rede, como mostrado no exemplo de código abaixo:</p>
    <p>Exemplo de código 4:</p>
    <p>Nesse exemplo, a compilação discrimina que há um arquivo de pesos através do texto sample_weight_mode=None. Em seguida, no treino, é passado o array como ponderação a ser utilizada através do texto sample_weight=sample_weights. Dessa forma é possível determinar o quanto uma rede deve aprender de cada exemplo.</p>
    <h1>3.4.3 Performance</h1>
    <p>O tamanho da entrada batch_size no treino da rede define qual é a taxa de carregamento dos dados antes do backpropagation. Essa entrada possui relação direta com a performance da máquina. O valor da época (nb_epoch) também foi alterado para garantir que houvesse atualizações suficientes conforme o batch crescia. O resultado desses testes pode ser visto na Tabela 3.1.</p>
    <p>A partir dos dados foram feitas comparações para estimar onde há o maior ganho do processamento da placa de vídeo em relação a CPU, com o objetivo de tornar o treinamento mais rápido, mantendo a acurácia do modelo. A Figura 3.4 mostra a relação entre as duas unidades. Essa relação de ganho está expressa no gráfico como a linha amarela. Os valores do eixo inferior (tamanho Batch) foram expressos em escala logarítmica para facilitar a visualização. Pode-se observar que o maior ganho está para valores menores do Batch e da Época. Porém a precisão do modelo decai muito para tais valores.</p>
    <p>Devido a perda da acurácia para valores baixos, foi necessário definir uma taxa de performance para cada unidade de processamento. Tal taxa era necessária para se verificar onde há real ganho de custo de processamento em relação a acurácia obtida. Para seu cálculo foi definido como performance a Acurácia sobre o Tempo de cada unidade. O cálculo foi multiplicado por 1000 para que houvesse acerto da escala de ambos. Os valores do Batch foram expressos em escala logarítmica para facilitar a visualização. O resultado pode ser visto na Figura 3.5</p>
    <p>A região que compreendia o Batch de tamanho 8 até 64 se destaca em relação às demais em termos de performance. Dessa forma considerou-se encontrar um máximo local nessa região. A Tabela 3.2 expressa os valores obtidos para a região entre Batch 8 e 64 e época 8 e 32.</p>
    <p>Esta tabela pode ser traduzida no gráfico da Figura 3.6, onde é apresentada a performance local para cada valor combinação de Batch e época.</p>
    <p>Da gráfico obtém-se um máximo local para quantidade de épocas 8 e Batch 32. Dessa forma esses valores foram utilizados na nos treinos subsequentes da rede.</p>
    <h1>3.5 Comentários Finais</h1>
    <p>Na camada de Dropout, a probabilidade escolhida foi de 0.5 (50%) na retirada de cada neurônio, o que maximiza o resultado dessa camada [43]. Valores diferentes apresentaram diminuição da efetividade.</p>
    <p>Os testes iniciais de performance foram realizados com a relação entre batch e época iguais. Isso se deve pois a rede só realiza o backpropagation (atualização dos pesos da rede) após o término de cada batch. Assim, para comparar a performance entre um valor de batch e outro, era necessário manter a quantidade de atualizações da rede constante. Portanto, quando se divide a quantidade de vetores pelo tamanho do batch (atualizações da rede por época) e depois se multiplica pela quantidade de épocas, ao final a quantidade de atualizações na rede permanece a mesma se o valor do batch e época são iguais.</p>
    <h1>Capítulo 4</h1>
    <p>Resultados Obtidos</p>
    <p>Diversos cenários foram considerados para teste das soluções possíveis. Tais cenários podem ser classificados em quatro casos de teste principais, alguns com ramificações, mas seguindo a mesma ideia. Os casos foram considerados conforme o objetivo de cada teste, que é a verificação das relações entre os dados e as acurácias da RNA.</p>
    <h1>4.1 Caso 1</h1>
    <p>No primeiro caso foram analisados os dados in natura, com o objetivo de verificar o comportamento deles e a complexidade do problema. Uma rede simples de três camadas foi criada seguindo o modelo do primeiro exemplo de código. Cada rede composta de 1441 neurônios de entrada e 718 neurônios na camada de saída, conforme representação da Figura 4.1. O número de neurônios da camada escondida, variava para cada sequência de experimentos. Foi inicialmente estimado para, a primeira sequência, a metade da média geométrica dos números de neurônios das camadas de entrada e saída, ou seja 509. Em seguida foi repetido para os valores de 1018 neurônios, e 2160. Houve 10 experimentos para cada sequência. Foi utilizada a função de ativação sigmoide como saída de todas as camadas, assim como o otimizador SGD.</p>
    <p>A média dos resultados dos experimentos pode ser vista nas tabelas Tabela 4.1 de treino e Tabela 4.2 de teste, respectivamente.</p>
    <p>Uma acurácia média de 76% foi obtida no treino de redes com 2160 neurônios na camada intermediária. Os resultados obtidos mostram que a rede sempre retorna a aplicação de maior frequência como resultado da simulação, através da observação da distribuição dos valores na matriz de confusão, que estava concentrada no produto três, conforme Figura 4.2.</p>
    <p>Para esse caso, a rede neural aprendeu a aplicar apenas no produto com maior quantidade de aplicações, devido ao forte desbalanceamento dos dados</p>
    <h1>4.2 Caso 2</h1>
    <p>No segundo caso foi verificado o ganho de acurácia ao se inserir duas camadas de Dropout, antes e depois da camada intermediária. Esse caso verifica se há overfitting no treino do caso 1, seguindo os mesmos padrões do caso anterior. Foram definidos 1441 neurônios de entrada da rede, 718 neurônios na camada de saída e as camadas intermediária variando conforme os valores: 509, 1018 e 2160. Todas as camadas possuíam a função de ativação Sigmoide e otimizador SGD. Foram realizados 10 treinos e testes para cada rede criada. A média dos resultados obtidos no treino e testes seguem das tabelas Tabela 4.3 e Tabela 4.4 respectivamente</p>
    <p>Mesmo com o risco de overfitting diminuído pela camada Dropout, o resultado foi similar ao caso anterior. O que demonstra que a rede não está sendo comprometida com o excesso de treino.</p>
    <h1>4.3 Caso 3</h1>
    <p>No terceiro caso foi verificada se a adição de mais uma camada intermediária afetaria a acurácia da rede neural. Esse caso tem por objetivo eliminar a possibilidade de uma rede com apenas uma camada intermediária ter a capacidade limitada por falta de complexidade. Foi criada uma rede com 1441 neurônios de entrada, 718 neurônios na camada de saída. As duas camadas intermediárias tiveram os valores 1018 e 855 para a primeira sequência de experimentos, 2160 e 1710 para a segunda sequência. Todas as camadas possuíam a função de ativação Sigmoide e otimizador SGD. Foram realizados 10 testes para cada configuração. Os resultados dos testes e treinos podem ser vistos nas tabelas Tabela 4.5 e Tabela 4.6, nesta sequência.</p>
    <p>Não foi observado ganho com a utilização da segunda camada intermediária (oculta) de neurônios, o que demonstra que a complexidade do problema não está limitada pelo número de camadas ou quantidade de neurônios, para o caso simples com a função de ativação Sigmoide.</p>
    <h1>4.4 Caso 4</h1>
    <p>No quarto caso foi verificado se havia a ocorrência de overfitting para as redes com duas camadas intermediárias de neurônios do caso 3. Foi feita a adição da camada de Dropout intercalando cada camada das redes montadas no caso anterior, exceto na última camada.</p>
    <p>Foi adotada essa estratégia a fim de detectar se a performance da adição da segunda camada intermediária estava limitada pelo excesso de dados. Seguindo os moldes do caso anterior, foi criada uma rede com 1441 neurônios de entrada e 718 neurônios na saída. Foram executados 10 experimentos com camadas intermediarias de 1018 e 855 neurônios, assim como com as camadas intermediárias de 2160 e 1710. Todas as camadas possuíam a função de ativação Sigmoide e otimizador SGD. Os resultados dos testes e treinos podem ser vistos nas tabelas Tabela 4.7 e Tabela 4.8, respectivamente.</p>
    <p>Com a introdução da camada de Dropout pode-se comprovar que o excesso de treino também não afeta o resultado geral da rede com mais camadas intermediárias de neurônios.</p>
    <h1>4.5 Caso 5</h1>
    <p>No quinto caso verificou-se se há influência da função de ativação em relação ao resultado obtido no primeiro caso. Desse modo foram feitos os mesmos experimentos com funções de ativação diferentes da Sigmoide. Foi criada uma rede com uma camada de entrada como 1441 neurônios e função de ativação relu (Unidade Linear Retificada) e uma camada de saída com 718 neurônios e função de ativação softmax (Função Exponencial Normalizada). Para a camada intermediária foram abordadas as configurações de 509, 1018, 2160 e 4320 neurônios. Estas camadas possuíam a função de ativação relu. Foram realizados 10 experimentos para cada configuração da rede. Os dados obtidos para os treinos seguem da Tabela 4.9 e os dados obtidos para os testes seguem da Tabela 4.10.</p>
    <p>Em termos semânticos, obteve-se resultados diferentes dos apresentados anteriormente. O resultado da Matriz de Confusão destes testes possui um comportamento mais próximo da diagonal da matriz para várias aplicações, como pode ser visto em parte na Figura 4.3. Esse comportamento é mais desejado para solução do problema, uma vez que, apresenta diversidade nas aplicação sugestionadas.</p>
    <h1>4.6 Caso 6</h1>
    <p>No sexto caso, verificou-se a influência do uso de Dropout em relação ao resultado obtido no quinto caso. Desse modo, procura-se mitigar a possibilidade de overfitting no treino do caso anterior. As camadas de Dropout foram intercaladas com cada camada de neurônios da rede, exceto a última. Foi criada uma rede com uma camada de entrada como 1441 neurônios e função de ativação relu e uma camada de saída com 718 neurônios e função de ativação softmax. Para a camada intermediária foram abordadas as configurações de 509, 1018, 2160 e 4320 neurônios. Estas camadas possuíam a função de ativação relu. Foram realizados 10 experimentos para cada configuração da rede. Os dados obtidos para os treinos seguem da Tabela 4.11 e os dados obtidos para os testes seguem da Tabela 4.12.</p>
    <p>Em comparação com os dados obtidos no quinto caso, não houve melhora na acurácia, de modo que o excesso de dados não afeta o treino da rede neural.</p>
    <h1>4.7 Caso 7</h1>
    <p>No sétimo caso, verificou-se o efeito da mudança da função de ativação para o caso 4, onde a rede possui duas camadas intermediárias intercaladas com as camadas de Dropout. Com a melhora na interpretação da rede para as novas funções de ativação, foi necessário verificar se a camada adicional e as camadas de Dropout representam ganho na acurácia. Foi criada uma rede com 1441 neurônios de entrada com função de ativação relu e 718 neurônios na saída com função softmax. Foram executados 10 experimentos com camadas intermediarias de 1018 e 855 neurônios, com as camadas intermediárias 2160 e 1710 e com camadas . Essas camadas possuíam a função de ativação relu. Intercalando cada camada de neurônios havia uma camada de Dropout. O otimizador utilizado foi o SGD. Os resultados dos testes e treinos podem ser vistos nas tabelas Tabela 4.13 e Tabela 4.14, respectivamente.</p>
    <p>Para o sétimo caso houve diminuição da variância em relação ao quarto caso. Mesmo que não houvesse melhora na acurácia, a precisão das previsões melhorou. Em termos semânticos, foi detectada maior distribuição de valores ao longo da diagonal inversa da Matriz de Confusão, fato que não foi observado no caso 4.</p>
    <h1>4.8 Caso 8</h1>
    <p>Conforme observado no caso 1, as quantidades de investimentos em determinados produtos tendenciarçam a rede a prever as aplicações com maiores frequências. Com o objetivo de mitigar a influência de tais aplicações, foram feitos testes que limitavam a quantidade de amostras por aplicação, de modo que fosse compensado o desbalanceamento dos dados. Os dados foram divididos nos conjuntos de no máximo um exemplar por aplicação, máximo de 10 exemplares por aplicação, máximo de 100 exemplares por aplicação, máximo de 1000 exemplares por aplicação e máximo de 10000 exemplares por aplicação. Para cada conjunto foram realizados 10 experimentos. Os experimentos foram testados 3 vezes, uma com o conjunto de treino, outra com o conjunto de treino original, envolvendo todos os registros, e outra com o conjunto de teste. A rede criada segue os padrões do caso 5, para uma camada intermediária de 2160 neurônios com função de ativação relu, uma camada de entrada de 1441 neurônios com função de ativação relu e uma camada de saída de 718 neurônios com função de ativação softmax. Os resultados dos testes, testes originais e treinos podem ser vistos nas tabelas Tabela 4.15, Tabela 4.16 e Tabela 4.17, respectivamente.</p>
    <p>Para o oitavo caso, pode ser observado como a distribuição afetou a acurácia. Devido a discrepância entre as quantidades de aplicações, a rede não consegue decidir corretamente quando se limita essas quantidades. Isso se deve pelas redes, com menor número de vetores de treino, se tornarem altamente especializadas, o que explica os altos índices de acerto no conjunto de treino, mas a deficiência de acerto no conjunto original de treino ou de teste. Porém, pode-se notar que há uma dispersão maior dos dados no gráfico de matriz de confusão o que implica em uma maior distribuição em diferentes tipos de aplicação antes sequer considerados como resultado das simulações. Mesmo assim a manipulação do desbalanceamento não contribuiu com a acurácia da rede.</p>
    <h1>4.9 Caso 9</h1>
    <p>Com o objetivo de utilizar as dispersões das simulações obtidas no caso anterior e compensar o desbalanceamento das aplicações, sem alterar o arquivo de entrada, foi criada uma rede composta por cinco redes de entrada, onde cada rede é treinada separadamente. Cada rede se especializa em um conjunto de dados como no caso anterior. Após os treinamentos, essas redes são congeladas (seus pesos não são mais atualizados) e servirão de entrada de uma rede composta.</p>
    <p>Para o treinamento das sub-redes, o arquivo de entrada é dividido em aplicações cujo critério para divisão é a frequência de aplicações. O critério de divisão dos arquivos é definido como: até 1 registro por aplicação, até 10 registros, até 100 registros, até 1000 registros e até 10000 registros, seguindo os moldes do exercício anterior. Dessa forma, os resultados do treino das sub-redes também seguem o exercício anterior.</p>
    <p>Cada sub-rede possui 1441 neurônios de entrada, uma camada intermediária de 1018 neurônios e 718 neurônios na camada de saída. As funções de ativação são relu para a camada de entrada, relu para a camada intermediária e softmax para a saída. Esta configuração foi adotada seguindo o modelo do caso 5, por possuir uma boa dispersão das saídas. Após o treino, essas redes são congeladas, ou seja não ocorre mais sua atualização nos próximos treinos. Para a criação da rede que englobaria as outra foi criada uma camada intermediária de 3661 neurônios com função de ativação relu e uma camada de saída com 718 neurônios com função softmax.</p>
    <p>Foram realizados 10 treinamentos para cada sub-rede. Os dados obtidos seguem da Tabela 4.18.</p>
    <p>Para o nono caso, pode ser observado que a subdivisão em redes menores, prétreinadas, não representou ganho na acurácia da rede. Dessa forma, compensar o desbalanceamento dos dados através de especialização, não apresenta ganho para o problema proposto, no caso da utilização de sub-redes congeladas. De fato, a rede voltou aos estados iniciais dos primeiros experimentos, onde sempre se tendia a aplicar no mesmo produto. Este experimento revela que o congelamento das sub-redes não é uma abordagem válida, ao menos sem garantir que a rede maior também tenha acesso aos dados integrais de treino.</p>
    <h1>4.10 Caso 10</h1>
    <p>Para o décimo caso, foi realizada uma abordagem alternativa para o problema. A abordagem consiste na modificação da entrada em diversas outras. Tais entradas servem de insumo para diversas redes que ao final são agrupadas. As modificações consistem em substituir as linhas da entrada cujas aplicações sejam as mais frequentes por zeros. Dessa forma, as entradas tem o mesmo número de linhas entre si, porém somente as linhas que pertencem às aplicações menos frequentes são preenchidas. Cada entrada é processada por uma rede. As redes são integradas em uma saída através de uma camada de integração (merge).</p>
    <p>Essa metodologia tem o objetivo de introduzir o cálculo do erro na parte da rede que possua os produtos com mais aplicações, sem atualizar a parte da rede dos produtos com menos. Isso ocorre devido ao momento em que se está processando os produtos com mais frequência, a entrada da rede dos produtos com menos estar zerada. Dessa forma, não é calculado o erro para essa parte da rede e os valores dos pesos não são atualizados.</p>
    <p>Ao se introduzir o erro na parte da rede com os produtos mais frequentes, tem-se o objetivo de diminuir sua importância na classificação das aplicações, melhorando o desempenho.</p>
    <p>A rede foi composta por três entradas, uma com todos os registros, uma com as linhas cujas aplicações do produto mais aplicado foi substituída por zeros e uma com as linhas cujas aplicações dos oito produtos mais aplicados foram substituídas por zeros. Cada entrada possui uma rede de 1441 neurônios associados, uma camada de integração (merge) por concatenação das redes, uma camada intermediária de neurônios e uma camada de saída de 718 neurônios. A quantidade de neurônios da camada intermediárias foi alterada a cada experimento. A representação da rede pode ser vista na Figura 4.4. A camada intermediária varia de tamanho conforme os valores: 509, 1018, 2160 e 4320. As funções de ativação são relu para todas as camadas, exceto a última cuja função é a softmax. A Tabela 4.19 e a Tabela 4.20 possuem os valores respectivos para o treino e teste da rede.</p>
    <p>No décimo caso, pode-se observar como o método de separação das entradas é mais eficiente no tratamento de entradas desbalanceadas. Esse método compensa as distâncias nas quantidades dos dados sem comprometer os mesmos, o que demonstra um forte acoplamento entre as aplicações realizadas e a acurácia do modelo. Isolar as aplicações por ocorrências é um avanço significativo para a interpretação da rede. A Figura 4.5 demonstra como há uma dispersão mais acentuada das aplicações na Matriz de Confusão, o que significa a melhora na interpretação da rede.</p>
    <h1>4.11 Caso 11</h1>
    <p>Para o décimo primeiro caso, foi realizada a mesma abordagem do caso 10, porém utilizando o conceito de ponderação no aprendizado da rede. Nesse conceito, a atualização dos pesos da rede depende do peso associado ao vetor de treino. Cada vetor possui o peso inversamente proporcional à frequência da aplicação referente ao mesmo. Por exemplo, se o vetor é referente a uma aplicação que aparece 50 vezes no conjunto de treino, então o peso associado ao vetor é 1/50. O objetivo deste caso é verificar se a influência das aplicações mais frequentes pode ser reduzida ainda mais, aumentando a acurácia da rede. A rede criada possuía 2160 na camada intermediária com função de ativação relu. As outras características eram idênticas a do caso 10. Foram executados 10 testes para essa rede. Os dados de treino e teste seguem das tabelas Tabela 4.21 e Tabela 4.22 respectivamente. No décimo primeiro caso, constatou-se que a introdução de pesos que compensassem a frequência das aplicações, igualando essa frequência através da taxa de aprendizagem, não representou ganho para a rede. A rede passou a não aprender os casos mais frequentes, o que trouxe similaridade com os resultados apresentados no experimento com até uma aplicação do caso 8, ou seja, aplicações com até 1 ocorrência foram preteridas em relação as demais. Esse método foi equivalente a ter treinado a rede com um conjunto de dados diferente, o que ocasionou o baixo desempenho.</p>
    <h1>4.12 Validação da Rede Neural Artificial</h1>
    <p>O resultado geral dos experimentos, observando o melhor resultado para cada caso, segue da Figura 4.6. Esse resultado mostra a predominância do caso 10 ante os demais. Os valores do caso 11 não são mostrados, pois distinguem-se muito da escala dos demais. Através da simulação da rede neural do caso 10 foi possível a verificação da efetividade da mesma. Utilizando a rede previamente treinada para o caso e simulando-a com a base de testes, foi possível identificar quais produtos representaram ganho na rentabilidade das carteiras dos clientes. Em um primeiro passo foi calculado o valor máximo de aplicação do produto antes que a carteira fosse desenquadrada. Em seguida, o valor calculado foi adicionado a carteira e os percentuais de todos os produtos foram recalculados em relação ao novo valor total da carteira. Cada percentual foi multiplicado pelo valor da rentabilidade do respectivo produto e os resultados das multiplicações foram somados.</p>
    <p>Ao final, aproximadamente 61% do conjunto de testes tiveram ganho de rentabilidade, 4% se manteve com a mesma rentabilidade e 35% perdeu rentabilidade. Dessa forma, a rede melhorou ou manteve iguais os investimentos em 65% dos casos, ainda mantendo os clientes enquadrados.</p>
    <h1>4.13 Comparação com trabalhos Correlatos</h1>
    <p>Os trabalhos apresentados sobre o tema de investimentos vinculados a redes neurais artificiais, conforme exposto anteriormente, possuem proximidade com o abordado neste trabalho. Dentre as características abordadas nos trabalhos correlatos, pode-se verificar como predominantes:</p>
    <ul>    
        <li>Concentram-se em áreas específicas de aplicações, que possuem características mais controladas para o treino da rede;</li>
        <li>As comparações de risco de produto utilizam o cálculo da teoria da Markowitz, que relaciona a covariância entre produtos para a formação de carteiras;</li>
        <li>Tentam deduzir qual a próxima melhor aplicação levando em consideração séries históricas dos valores de ativos.</li>
    </ul>
    <p>As características tratadas também limitam o oferecimento de um bom produto, pois excluem uma série de fatores que são importantes para os investidores. Tais fatores podem ser elencados como:</p>
    <ul>
        <li>Oferecem produtos sem considerar a legislação vigente, no que tange à API;</li>
        <li>Consideram uma aplicação equivalente a outra sem incorporar os interesses do investidor para a aplicação em questão como: perfil de investimento, prazo de resgate, entre outros;</li>
        <li>Limitam as opções de investimento, pois apresentam quantidade reduzida de investimentos e de tipos de investimento.</li>
    </ul>
    <p>Mesmo apresentando proximidade de temas, há uma grande distância entre a produção acadêmica atual e o tema deste trabalho. Tendo em vista as limitações do problema em questão e pelos fatores anteriormente apontados, o mesmo se tornou ímprobo de correlação.</p>
    <h1>4.14 Comentários Finais</h1>
    <p>As redes criadas tiveram sua acurácia medida para os dados dos melhores clientes enquadrados. Dessa forma, acertar o resultado da classificação para uma determinada entrada significa que a RNA oferecerá um produto baseada no que é mais comum nas aplicações dos melhores aplicadores, levando em consideração seu perfil de investidor. Isso não significa que, mesmo que tenha errado para algumas entradas, o produto oferecido não seja um bom investimento. Pode ocorrer a possibilidade de ser um produto melhor do que o conjunto de treino sugeriu. Devido a complexidade do segmento de investimentos, não há como afirmar se foi bom ou ruim até que seja exercido o resgate do mesmo.</p>
    <h1>Capítulo 5</h1>
    <h1>Conclusão</h1>
    <p>Neste trabalho foi apresentado uma aplicação de Redes Neurais Artificiais (RNA) no oferecimento de produtos de investimento, através da análise do perfil do investidor e carteira de investimentos que possui.</p>
    <p>O estudo é parte de uma solução para oferecimento, de forma automatizada, de um bom investimento, considerando a situação específica de um cliente. De forma geral, foi realizado o treino de uma RNA que possui como entrada o comportamento padrão do cliente em relação aos investimentos e como saída uma aplicação. Para o treino, foram considerados os melhores investidores de uma instituição financeira, de modo que a rede aprendesse a imitar o comportamento desses investidores, ofertando bons produtos de investimento. Outra preocupação na criação da rede foi considerar apenas investidores que estivessem com os investimentos aderentes ao seu perfil de investidor, o que traz segurança no investimento ofertado, uma vez que diminui a probabilidade de oferta de investimentos fora do padrão de consumo do cliente.</p>
    <p>A simulação levou em conta os investimentos realizados no mês de setembro de 2016. Devido ao enorme fluxo de aplicações da instituição escolhida, não houve carência de dados. Para tratar do volume elevado, técnicas para otimizar a performance das redes, como a utilização de placas gráficas no processamento, foram utilizadas. Os dados apresentados possuíam grande desbalanceamento. Para compensar isso, diversas soluções de contorno tiveram de ser testadas. Bibliotecas pré-formatadas para trabalho com redes neurais através da linguagem de programação Python foram utilizadas, o que diminuiu o tempo de criação e possibilitando o teste dessas diversas redes.</p>
    <p>A rede que apresentou o melhor resultado foi a rede do caso 10. Neste caso, a RNA é composta por 3 sub-redes. A primeira sub-rede contempla todo o conjunto de dados, a segunda possui entradas zeradas para a aplicação de maior frequência e a terceira com entradas zeradas para as 8 aplicações de maior frequência. A saída de cada sub-rede é ligada a uma rede maior. A saída da rede maior representa cada aplicação possível, onde a que possui a maior probabilidade é a escolhida como resultado da simulação.</p>
    <p>Através da subdivisão em redes menores, que contenham entradas diferentes da original, é introduzido erro na rede sempre que as aplicações mais frequentes são feitas, o que diminui seu grau de importância. A validade da rede foi verificada através do resultado da simulação da mesma para cada cliente, o investimento simulado é aplicado até o limite antes do desenquadramento. Para a maioria dos casos a rentabilidade total das carteiras aumentou.</p>
    <h1>5.1 Trabalhos Futuros</h1>
    <p>Como possíveis trabalhos futuros, pode-se apontar:</p>
    <ul>
        <li>Implementação da utilização de mais variáveis como entrada da RNA e verificação do efeito no desempenho da mesma, assim como, verificar se o resultado é mais adequado ao esperado pelos clientes. Um exemplo de possíveis entradas que se pode elencar são as características da data em que a aplicação foi realizada, como o dia do mês ou o mês de aplicação. Esse exemplo pode melhorar a interpretação do comportamento de cada investidor, através da separação dos investidores esporádicos e profissionais, dado que investidores profissionais tendem a aplicar em dias diferentes dos investidores esporádicos, ou pela época em que um investimento tem maior probabilidade de ser adquirido. Outro exemplo de entrada que teria efeito na performance do modelo seria a classificação das perspectivas econômicas nacional e global. Esse exemplo seria importante para aplicações de longo prazo que podem ser mais afetadas por tais perspectivas.</li>
        <li>Verificação teórica da abordagem utilizada para compensar o desbalanceamento das aplicações utilizada no Caso 10. Verificar os motivos pelos quais a técnica de manipulação das entradas, sem alterar suas características, pode ser empregada na melhora da interpretação da rede.</li>
        <li>Implementação de outras técnicas de aprendizagem de máquina, tais como Maquinas de Vetores de Suporte e Árvores de Decisão, com objetivo de comparação dos resultados. Essa implementação pode identificar outras técnicas que possuam maior precisão e performance em comparação com as RNAs para o problema em questão.</li>
        <li>Implementação de limitações das aplicações na decisão do cliente. Um exemplo de limitação seria o prazo que o cliente pretende resgatar o investimento. Outro exemplo seria se o investimento deve possuir as características de aplicação automática ou investimento automático. Tais limitações impediriam que fossem ofertados produtos sem essas características, o que muda os dados de treino da mesma.</li>
    </ul>
</body>
</html>