Um Estudo de Redes Neurais Recorrentes no Contexto de Previsões no Mercado Financeiro
Lucas Pimenta Vasco
Trabalho de conclusão do curso de graduação em engenharia de computação submetido ao corpo docente do Departamento de Computação da Universidade Federal de São Carlos como parte dos requisitos necessários para obtenção do título de engenheiro de computação.
Resumo
Predição de séries temporais financeiras é uma das aplicações de inteligência artificial mais estudadas por pesquisadores do mercado financeiro, tanto no mundo acadêmico quanto no corporativo. Dentro dessa área, há um grande destaque para a predição de valores de ações, principalmente devido à possibilidade de rentabilidade. Uma das técnicas mais utilizadas para fazer esse tipo de predição é a aplicação de redes neurais artificiais.
Esse trabalho é focado em uma das classes de redes neurais artificiais, as redes neurais recorrentes. São utilizados três tipos de arquitetura dessa área: o modelo de redes neurais recorrentes simples (VRNN) o Long Short Term Memory (LSTM) e o Gated Recurrent Unit (GRU). Ao longo do trabalho são criados modelos de cada uma dessas arquiteturas para três ações diferentes da bolsa de valores brasileira, mais especificamente das ações do Grupo Fleury (FLRY3), da Petrobras (PETR4) e da Vale (VALE3). Os modelos criados para cada uma das ações fazem uma predição dos valores dessas ações, e os resultados são comparados entre si com a intenção de avaliar qual predição obtém os valores mais próximos dos valores reais. As medidas de erro utilizadas nesse trabalho são o erro absoluto médio e o erro quadrático médio. Ao final, concluiu-se que os modelos GRU e LSTM obtém resultados semelhantes, com um desempenho um pouco melhor do GRU, e o VRNN conseguiu detectar padrões nos dados, mas não com tanta precisão quantos os outros.
INTRODUÇÃO
A predição bem-sucedida de dados de séries financeiras temporais sempre foi muito visada. A previsão do preço de ações, algorithmic trading, precificação de ativos, alocação de portfólio, entre outras, são áreas que despertam interesse de pesquisadores e investidores, por causa da possibilidade de rentabilidade. Devido à natureza volátil e não linear de dados do mercado de ações, depara-se com técnicas de Aprendizado de Máquina (AM) como forma de modelar, visto que o cérebro humano possui características desejáveis em qualquer sistema artificial. Entre elas estão a flexibilidade para se adaptar a situações, aprender com a experiência, a capacidade para lidar com informações inconsistentes e de reconhecer e generalizar padrões. Sendo assim, para se alcançar boas predições, a criação de modelos de AM vem sendo amplamente explorada.
O valor de uma ação é o maior valor pelo qual alguém quer vender essa ação, ou o menor valor pelo qual alguém a quer comprar, o que faz da oferta e demanda um fator decisivo para a definição de seu preço. Se muitas pessoas querem comprar uma ação, seu preço aumenta devido à alta demanda, e se muitas pessoas a quiserem vender, a alta oferta faz o seu preço abaixar. O conceito é fácil de ser compreendido, o problema é compreender os fatores que influenciam na variação da oferta e demanda. Apesar de parecer ser uma tarefa muito complicada, há anos são usadas técnicas de inteligência artificial para prever o preço de ações, sendo possível encontrar exemplos até de 1994. Com o avanço da tecnologia nas últimas décadas, os modelos de Deep Learning (DL) vêm se destacando cada vez mais entre os modelos utilizados para esse propósito.
No contexto de predição do valor de ações, são feitos estudos com base em diversas classes de Redes Neurais Artificiais (RNA). Kim aplica SVM para classificar a direção do índice do mercado de ações coreano usando indicadores de análise técnica como variáveis preditivas. Kim e Han utilizou um algoritmo genético para discretização dos valores contínuos dos indicadores de análise técnica, com a finalidade de otimizar os pesos de uma RNA, resultando em uma melhor predição. Pai e Lin combinou SVM com um modelo Autoregressive Integrated Moving Average (ARIMA) em um sistema híbrido com erros menores do que os obtidos pelos modelos utilizados separadamente. Chen, Cheng e Tsai utiliza lógica fuzzy em uma série temporal, com o objetivo de superar limitações relativas a suposições de linearidade presentes em outros modelos, como o ARIMA. Porém, os modelos de DL que se mostraram mais estudados e que obtiveram melhores resultados quando comparados a outros tipos de modelo nesse contexto são os de Redes Neurais Recorrentes (RNR).
É importante também citar outros trabalhos como o de Wang, Xu e Zheng e de Iwasaki e Chen, que mostram uma abordagem inovadora, utilizando métodos de interpretação de textos relacionados a investimentos em ações retirados da internet para melhorar significativamente a previsão de seus modelos. Wang, Xu e Zheng inclusive propõe um novo modelo chamado de deep random ensemble, que mistura múltiplos modelos de AM e obtém resultados impressionantes.
O objetivo desse projeto é focar na predição dos valores de ações de empresas registradas na B3, a bolsa de valores brasileira utilizada para câmbio de ações, utilizando RNRs e comparar os resultados obtidos com cada modelo. Os três tipos de RNRs utilizados para comparação nesse trabalho são: Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), e a RNR simples, também conhecida como Vanilla Recurrent Neural Network (VRNN).
Motivação
Com o objetivo de ter o conhecimento das tendências de ações, visando um maior lucro e garantia, o interesse de investidores do mercado financeiro em métodos precisos de predição do valor de ações é muito grande. Conforme novas tecnologias surgem, são feitos estudos da acurácia dos diferentes tipos de modelos disponíveis, muitas vezes usando mais de uma técnica, com a finalidade de diminuir o erro dos modelos e por consequência aumentar a precisão das predições. Além disso, é possível utilizar outras técnicas para automatizar a compra e venda de ativos de acordo com esses modelos criados, facilitando ainda mais o processo.
Pelo interesse do autor em investimentos de ações no mercado financeiro, e com uma ampla gama de métodos disponíveis para predição dos valores futuros, esse trabalho apresentou uma oportunidade de testar algumas das técnicas de AM e validar a possibilidade do uso de modelos de RNR como uma opção viável de ser utilizada para investimento.
Objetivos
Este trabalho tem como objetivo realizar um estudo sobre RNRs aplicadas ao mercado de ações, treinando modelos com 3 datasets de ações diferentes encontrados na bolsa de valores brasileira, tais como FLRY3, PETR4 e VALE3. Para averiguar a precisão das predições, o Erro Quadrático Médio (EQM) e o Erro Absoluto Médio (EAM) de cada modelo será analisado. Assim, será possível concluir qual tipo RNR provê melhores resultados.
Adicionalmente, o trabalho propõe um estudo dos hiperparâmetros que podem ser modificados para esses tipos de RNA, identificando a combinação que traz o menor erro durante o teste. Posteriormente, os hiperparâmetros considerados como ótimo são aplicados em todos os modelos testados.


Fundamentação teórica

Séries Temporais
Uma série temporal é uma sequência de valores de uma variável observadas ao longo do tempo. A ordem dos dados é fundamental e os valores vizinhos são dependentes. Logo, um dos interesses é analisar e modelar esta dependência.
A série temporal pode ser contínua, quando os valores são observados continuamente, ou discreta, quando os valores são observados em tempos específicos, normalmente equiespaçados. Essa terminologia se refere ao espaçamento dado entre as observações e não ao tipo da variável resposta. Conceitualmente, uma série temporal com n observações possui a seguinte representação: periquito, onde periquito são valores de periquito é a série temporal e as variáveis periquito a periquito são amostras da série no período periquito.
Segundo a abordagem de componentes não observáveis, as séries temporais podem ser representadas como a combinação de quatro componentes: Tendência, Cíclica, Sazonal e Erro.
As componentes de tendência frequentemente produzem mudanças graduais em longo prazo, podendo ser de crescimento ou decrescimento. Um exemplo é o crescimento constante na população.
As componentes cíclicas são aquelas que provocam oscilações de subida e de queda nas séries, de forma suave e repetitiva, ao longo da componente de tendência. Geralmente os efeitos cíclicos em uma série são causados por mudanças na demanda do produto, por ciclos de negócios e, em particular, pela inabilidade de se suprir as necessidades do consumidor.
As componentes sazonais em uma série são aquelas oscilações de subida e de queda que sempre ocorrem em um determinado período do ano, do mês, da semana, do dia ou horário. Por exemplo, é natural esperar que as vendas mensais de brinquedos terão um pico no mês de outubro, devido ao dia das crianças. Este padrão possivelmente se repetirá ao longo de vários anos.
A diferença essencial entre as componentes sazonais e cíclicas é que a primeira possui movimentos facilmente previsíveis, ocorrendo em intervalos regulares de tempo. Já os movimentos cíclicos tendem a ser irregulares.
A quarta componente da série, chamada de erro, apresenta flutuações de período curto, com deslocamento inexplicável e geralmente são causadas, entre outros motivos, por eventos políticos, econômicos e oscilações climáticas imprevisíveis.
Os modelos de previsão podem ser classificados em univariados, os quais têm a previsão dos valores futuros explicados somente pelos valores passados da própria série ou causais, ou os que levam em conta outras informações relevantes (covariáveis) como influentes para a previsão de uma variável resposta.
Segundo Shumway e Stoffer, o principal objetivo da análise de séries temporais é desenvolver modelos matemáticos que consigam descrever uma certa amostra de dados, a fim de identificar o comportamento desses dados. Os modelos de previsão de séries temporais são capazes de definir, com certo grau de confiança, os valores futuros das séries a partir das observações passadas da própria série. O uso de modelos de previsão é importante, pois tem como caráter diminuir os riscos na tomada de decisão.

Inteligência artificial
Luger e Stubblefield definem Inteligência Artificial como o ramo da ciência da computação que trata da automação de comportamento inteligente. O surgimento dessa área foi um resultado natural da busca do ser humano pelo entendimento da forma como ele age e pensa. Com o desenvolvimento da ciência da computação e da neurociência, a IA passou a utilizar dessas duas áreas em busca da construção de entidades inteligentes.
A partir dessa definição, podemos dizer que um dos objetivos da IA, quando olhamos no contexto de Aprendizado de Máquina, é de construir e compreender inteligência, criando algo inteligente o suficiente para ter a capacidade de analisar dados e reconhecer padrões. Isto significa que, através da IA, é possível criar métodos preditivos analíticos, que serão melhor explorados no decorrer deste trabalho.
Os princípios da IA podem ser encontrados no trabalho de Turing, que propõe o chamado teste de Turing. O teste foi uma proposta para verificar o nível de inteligência de uma máquina, em que, caso o entrevistador humano não consiga diferenciar se o objeto entrevistado é uma máquina ou outro ser humano, essa máquina pode ser considerada inteligente. Segundo Russell e Norvig, para uma máquina ser considerada aprovada no teste, ela precisa ter as seguintes competências:
Processamento de linguagem natural, para possibilitar a comunicação; 
Representação de conhecimento, para armazenar o que ela aprende ou vê; 
Raciocínio automatizado, para usar a informação armazenada para responder perguntas e tirar novas conclusões; 
Aprendizado de máquina, adaptar a novas circunstâncias e detectar e extrapolar padrões.
Além dessas quatro competências, o chamado teste de Turing total, uma versão aprimorada, acrescenta ainda mais dois pontos:
Visão computacional, para compreender objetos;
Robótica, para manipular objetos e conseguir se movimentar.
Essas seis grandes áreas compreendem a maioria dos estudos e pesquisas de IA, fazendo o teste de Turing continuar sendo relevante mesmo décadas depois de ter sido proposto.
Nesse contexto, com o avanço da tecnologia, a capacidade computacional torna-se suficiente para grandes aplicações envolvendo Aprendizado de Máquina, que é um sub-área de Inteligência Artificial que usa algoritmos de aprendizado para construir sistemas que têm a capacidade de aprender e melhorar automaticamente com as experiências sem serem programados explicitamente.
No Aprendizado de Máquina, treinamos o algoritmo fornecendo-lhe muitos dados e permitindo que ele aprenda mais sobre as informações processadas. Conforme avançamos para a era do Big Data, temos um volume enorme de dados disponível para treinar essas aplicações. Visto que a capacidade humana de processamento de grandes volumes de dados parece limitada diante do potencial desses sistemas automatizados, eles podem trazem consigo a capacidade de remodelar a sociedade e a forma como ela trabalha, principalmente se tratando de situações específicas em que os algoritmos podem se especializar.
Ainda nessa linha, tem-se o conceito de Deep Learning, que procura imitar o cérebro humano e que pode ser definido como uma arquitetura de rede multi neural contendo um grande número de parâmetros e camadas. 
Na figura Figura 1 é possível ver o diagrama de Venn que elucida a composição de Inteligência Artificial, Aprendizado de Máquina e Deep Learning.

Aprendizado de Máquina
A área de Aprendizado de Máquina está relacionada com a questão de como construir programas de computadores que aprendem e aperfeiçoam-se automaticamente através da experiência. Os algoritmos de AM têm o intuito de achar padrões em um conjunto de dados e se otimizar através desses padrões. Esse tipo de algoritmo é responsável pela maior parte dos avanços e aplicações de IA utilizados no dia-a-dia, como por exemplo as recomendações dadas em diversos serviços de streaming, em detecção de fraudes, diagnóstico médico por imagens, chatbots, entre outros.
Uma grande parte de AM consiste na matemática usada em aprendizagem estatística e otimização de dados. Por isso, é muito importante a forma como os dados são representados. No contexto de predição através de redes neurais, se uma base de dados utilizada para a aprendizagem for bem estruturada, o algoritmo tende a reconhecer melhor os padrões do conjunto de dados.

Redes Neurais Artificiais
Redes Neurais Artificiais, também chamadas apenas de Redes Neurais, são uma estrutura computacional que atuam de forma semelhante à de neurônios biológicos. Os neurônios artificiais são conectados uns aos outros através de um mecanismo composto por um conjunto de pesos atribuídos.
Uma RNA é projetada para identificar uma tendência básica em um conjunto de dados, e fazer uma generalização a partir dela. A maior vantagem de uma RNA, quando comparada a outras técnicas de AM, é a sua capacidade de aprender os padrões subjacentes dos dados, onde a maioria dos métodos convencionais tende a falhar.
RNAs são construídas com base em uma rede de unidades de processamento que buscam simular um neurônio e que, nesse contexto, também são chamadas de neurônio. A conexão entre os neurônios são chamadas de sinapses, e cada neurônio que compõe a rede recebe informação de outro como entrada através das sinapses. Essa informação de entrada é multiplicada por um peso definido pelo construtor da rede, que é usado para ajustar a importância de diferentes resultados computacionais obtidos pelo neurônio.
O neurônio artificial, representado na Figura 2, possui periquito entradas periquito, e cada entrada é conectada ao neurônio através de sinapses com pesos periquito. O neurônio soma as entradas multiplicadas pelos pesos através da equação:
Onde A é o resultado da soma e b é o valor do viés (bias). Para calcular a saída, à soma é aplicada uma função chamada de função de ativação.

Função de ativação
O propósito da função de ativação é de restringir a saída de acordo com o problema proposto. Como dados financeiros tendem a ser não-lineares, esse fato sugere que funções não-lineares são mais apropriadas, tais como a função Sigmoide e Tangente Hiperbólica (Equação 1.2). Elas são comumente utilizadas em dados de séries temporais, porque são continuamente diferenciáveis, sendo esta uma propriedade desejável no treinamento da rede.

Processos de Aprendizado de uma Rede Neural Artificial
De acordo com GIRIOLI e RIBEIRO:
A rede neural se baseia nos dados para extrair um modelo geral. Portanto, a fase de aprendizado deve ser rigorosa. De 50% a 90% do total de dados devem ser separados para o treinamento da rede neural, dados estes escolhidos aleatoriamente, a fim de que a rede "aprenda" as regras e não "decore" exemplos. O restante dos dados só é apresentado à rede neural na fase de testes a fim de que ela possa "deduzir" corretamente o inter-relacionamento entre os dados.
O próximo passo é a definição da configuração da rede, que normalmente é feita de forma empírica. Em seguida, há o treinamento da rede. Nesta fase serão ajustados os pesos das conexões. Uma boa escolha dos valores iniciais dos pesos da rede pode diminuir o tempo necessário para o treinamento. O treinamento deve ser interrompido quando a rede apresentar uma boa capacidade de generalização e quando a taxa de erro for suficientemente pequena, ou seja, menor que um erro admissível.
O último passo é o teste da rede. Durante esta fase o conjunto de teste é utilizado para determinar a performance da rede com dados que não foram previamente utilizados. O desempenho da rede, medido nesta fase, é uma boa indicação de sua performance real.

Arquitetura
A forma como os neurônios são agrupados e conectados é conhecida como arquitetura da rede neural. Combinações de diferentes características podem ser feitas a fim de se obter redes com arquiteturas e aplicações bastante distintas.
Antes, é preciso definir dois aspectos importantes: o algoritmo de aprendizado que será implementado, sendo as formas mais comuns o algoritmo supervisionado e o não supervisionado; e a maneira como os sinais se propagam dentro da sua estrutura interna, determinando se a rede possui retroalimentação ou não, podendo ser classificada como não recorrente, recorrente, entre outras.

Aprendizado Supervisionado
No aprendizado supervisionado, a rede tem sua saída atual comparada com a saída desejada, recebendo informações sobre o quão apurada está a resposta atual, ou seja, são exibidos os valores corretos para cada par entrada-saída, de forma que a RNA possa ajustar seus pesos e diminuir o erro geral de treinamento.
Outro aspecto a ser determinado é de quando ocorrerá o processo de alteração dos pesos. Um método de treinamento que requer o processamento de todos pares-entradas (uma época) para só depois calcular a mudança nos pesos da rede é chamado de método de treinamento por lote (batch no inglês) ou por ciclo.
Existem métodos de treinamento que propõem que as alterações nos pesos sejam feitas após o processamento de cada par entrada-saída, sem esperar que todos os padrões sejam apresentados. Tais métodos são chamados de métodos de treinamento online ou Delta.
Os exemplos mais conhecidos de algoritmos de aprendizagem supervisionada são a regra delta e a sua generalização para redes de múltiplas camadas, o algoritmo backpropagation.

Aprendizado Não Supervisionado
No algoritmo não supervisionado, não existe um vetor de resposta desejada. Logo, a RNA realiza uma forma de compressão nos dados, agrupando os valores que apresentam padrões similares.
A rede neural reconhece um padrão passando por uma seção de treinamento, durante a qual se apresenta repetidamente um conjunto de padrões de entrada junto com a categoria a qual cada um pertence. Em seguida, apresenta-se à rede um padrão que nunca foi visto, mas que pertence a população de padrões utilizados para o treinamento e a rede. Por causa da informação extraída no aprendizado, a rede é capaz de identificar a categoria correta daquele padrão particular.
Para esse tipo de treinamento pode-se utilizar a regra de aprendizagem competitiva.

Redes Não Recorrentes
Outra característica a ser determinada é a direção do sinal de propagação das conexões, podendo ser feedforward ou backward, como ilustrado na Figura 4.
Nas redes não recorrentes ou redes diretas, o fluxo de sinal é apenas em um sentido.

Redes Neurais Recorrentes
Nas redes recorrentes, existe pelo menos um ciclo de retroalimentação, em que o sinal retorna para uma camada anterior, tornando o treinamento mais complexo, mas especializando a rede para certos tipos de aplicação, como dados sequenciais. A Figura 5 ilustra esse tipo de conexão.
Em mais detalhes, Redes Neurais Recorrentes são uma classe de redes neurais que recebe entrada de duas fontes: uma do presente, e outra de um ponto passado. A informação das duas fontes são utilizadas para decidir como reagir a uma nova entrada de dados, e isso é feito através de um circuito de feedback, onde a saída de cada instante é uma entrada para o instante seguinte. Devido a essa característica, podemos dizer que elas possuem memória, fazendo das RNRs mais semelhantes da forma como humanos processam informação, possibilitando o reconhecimento de um contexto através da memória.
Normalmente, RNRs são compostas por 3 tipos de camadas: camada de entrada, camada intermediária ou escondida, e camada de saída. Cada neurônio na camada de entrada é conectado com cada neurônio da camada intermediária seguinte, até a camada de saída. Em RNRs, é comum os modelos terem mais de uma camada intermediária.
A Figura 6 mostra uma representação de redes neurais recorrentes, onde a equação de entrada das camadas intermediárias é dada por:
onde é a camada intermediária no instante t, gn é a função de ativação, Wxh é a matriz de peso de entrada, Xt é a entrada no instante t, ht−1 é a camada intermediária no instante t − 1, Whh é a matriz de peso do neurônio recorrente, e bh é o valor de viés.
Já a equação da saída da camada intermediária é dada por:
onde Zt é o vetor de saída, Whz é a matriz de peso para a camada de saída, e bz é o viés (HIRANSHA et al., 2018).
O principal problema da RNR é que o gradiente da função de custo decai exponencialmente com o tempo e o modelo para de aprender. Esse problema é chamado de problema da dissipação do gradiente (HAYKIN, 2008).

Rede Long Short-Term Memory
A rede LSTM é uma variante especial de RNR capaz de aprender dependências de longo prazo. Ela foi projetada especificamente para evitar o problema de dissipação/explosão do gradiente. Uma LSTM é adequada para classificar e prever dados de séries temporais. A Figura 7 mostra uma representação gráfica da LSTM.
Essa arquitetura comum da célula de LSTM é composta por um estado da célula (ct), uma saída chamada de hidden state (ht), um input gate (It), um output gate (Ot) e um forget gate (Ft). As equações de uma célula LSTM podem ser definidas como:
Como podemos ver na Figura 7, o estado da célula é uma linha horizontal que passa através da rede inteira, carregando informação da célula anterior para a atual, e assim por diante. A decisão de guardar informação no estado da célula é tomada pelo forget gate. A saída do forget gate é adicionada ao estado da célula através de uma operação de multiplicação elemento a elemento. Já o input gate é composto por uma camada sigmoide e uma camada de tangente hiperbólica, e junta essas duas no estado da célula. A saída é formada por uma multiplicação elemento a elemento do output gate e a tangente hiperbólica (HIRANSHA et al., 2018).

Rede Gated Recurrent Unit
GRU é um outro tipo de arquitetura de RNR que procura resolver o problema de dissipação do gradiente. É uma rede similar à LSTM, mas de estrutura um pouco mais simplificada. A GRU utiliza apenas dois tipos de portões: update gate e reset gate (Cho et al., 2014). Esse tipo de rede possui menos parâmetros, e por isso geralmente é treinada mais rapidamente ou com um número menor de dados, mas, com um maior volume de dados, as LSTMs podem acabar apresentando resultados melhores (WEISS; GOLDBERG; YAHAV, 2018). A Figura 8 mostra uma representação da célula de GRU.
Nas equações acima, xt representa o vetor de entrada, ht o vetor de saída, h vetor candidato a ativação, zt é o vetor do update gate, e rt é o vetor do reset gate.

Medidas de Avaliação
A forma mais comum de medir a acurácia de um modelo de rede neural que prevê os valores futuros de ações é através do cálculo de erro do modelo. Quanto menor o erro de um modelo, melhor ele se ajustou ao conjunto de dados e mais próximo sua predição chegou dos valores reais. Nessa seção serão apresentados as duas medidas utilizadas ao longo desse trabalho: o Erro Absoluto Médio (EAM) e o Erro Quadrático Médio (EQM).

Erro Absoluto Médio
EAM é uma fórmula matemática que pode ser utilizada para calcular o erro das previsões dos modelos. É uma parte importante para o relatório, pois é fortemente baseado em estimativas e previsões futuras de conjuntos de dados. o erro absoluto médio é calculado  através da diferença do valor real e do valor predito dividido pelo número de dados:
onde xi é o i-ésimo valor real, yi é o i-ésimo valor predito e n é o número de dados utilizados.

Erro Quadrático Médio
O EQM é um outro método de calcular a acurácia e o erro nos modelos preditivos utilizados nesse trabalho. A equação do erro quadrático médio pode ser definida como: ,onde xi é o i-ésimo valor real, yi é o i-ésimo valor predito e n é o número de dados utilizados.

Trabalhos Relacionados
Nessa seção, serão apresentados trabalhos que abordam problemas semelhantes aos tratados nesse estudo, que utilizaram abordagens diversas, e que serviram de aprendizado para o aprofundamento no tema previsão de redes neurais aplicadas ao mercado financeiro. 
Iwasaki e Chen (2018) mostram em seu trabalho uma abordagem interessante, onde desenvolvem uma rede neural profunda que, além de utilizar os dados de ações da bolsa de valores de Tóquio e Osaka, considera também opinião de analistas, que indicam ações de relevância através de relatórios, usando métodos de interpretação de texto. Essa abordagem foca principalmente em dois tipos de redes neurais: a LSTM e a rede neural convolucional.
Já Wang, Xu e Zheng (2018) utilizam um algoritmo que procura em artigos de notícias de várias fontes e também em redes sociais opiniões do público em geral para influenciar seu modelo de predição, e finalmente propõem um novo modelo de aprendizado de máquina chamado Deep Random Subspace Ensembles (DRSE), que integra algoritmos de deep learning e métodos de ensemble learning (uma técnica que combina múltiplos algoritmos de aprendizado) para uma melhor mineração de dados, e mostra resultados impressionantes.
Além desses citados anteriormente, foram encontrados dois artigos que abordaram com a comparação de diferentes tecnologias de Deep Learning aplicadas na predição de valores de ações e de índices de ações, que possuem uma relação mais próxima com este trabalho, e serão melhor detalhados a seguir. Os dois trabalhos possuem objetivos semelhantes, com um deles tratando métodos de Deep Learning de forma mais abrangente, e o outro focando nos modelos de Rede Neural Recorrente.
O primeiro artigo consiste em um estudo da predição dos valores de ações de setores variados registradas na National Stock Exchange (NSE) da Índia e na New York Stock Exchange (NYSE), realizado pelos autores Hiransha et al. (2018), publicado na revista "Procedia Computer Science". Seu artigo é intitulado "NSE Stock Market Prediction Using Deep-Learning Models" (HIRANSHA et al., 2018).
O segundo trabalho é um outro artigo também publicado na revista "Procedia Computer Science" e foi desenvolvido pelos autores Saud e Shakya (2020). Com o título de "Analysis of look back period for stock price prediction with RNN variants: A case study on banking sector of NEPSE", ele foca em predizer os as ações do Nepal Investment Bank (NIB) e Nabil Bank Limited (NABIL) e comparar os resultados das redes neurais recorrentes (SAUD; SHAKYA, 2020).
Em ambos os trabalhos, os autores têm como foco a comparação de predições utilizando diferentes métodos, que serão descritos nas próximas seções.

Estudo de comparação de predições utilizando diferentes métodos de Deep Learning
O trabalho apresentado por Hiransha et al. (2018) aplica diversas técnicas de Deep Learning, incluindo redes neurais recorrentes, Perceptron Multicamadas (MLP, Multilayer Perceptron) e Redes Neurais Convolucionais (CNN, Convolutional Neural Network), para analisar dois mercados internacionais de ações diferentes, treinando os modelos com apenas uma ação do setor automotivo e os validando com ações dos setores bancário, automotivo, energético e de tecnológico.
Os autores utilizam conjuntos de dados contendo o símbolo da ação, preços de abertura, máximo, mínimo, último, fechamento, e médio, quantidade total negociada, volume de negócios e número de negociações. Desses dados, eles extraem apenas o preço de fechamento diário de cada ação, já que os investidores tomam a decisão de comprar ou vender cada ação baseada no preço de fechamento do mercado (HIRANSHA et al., 2018).
Através de várias predições utilizando diferentes parâmetros de tamanho da janela, que é o número de dados anteriores que são utilizados para realizar a predição, a fim de descobrir o tamanho de janela ótimo, com o menor valor de erro absoluto médio percentual, para ser utilizado nas comparações.
Definido o tamanho da janela que será utilizado, os autores treinam modelos RNR, LSTM, CNN e MLP utilizando dados da empresa automotiva TATA MOTORS de janeiro de 1996 até junho de 2015, e testando os modelos com dados das empresas Maruti, Axis Bank e HCL Technologies, com conjuntos de dados de 2007 até 2017. Depois desse primeiro teste, também é utilizado como teste conjuntos de dados do Bank of America e Chesapeak Energy, a fim de analisar se o modelo era capaz de identificar se o modelo era capaz de identificar padrões até de mercados distintos de ações.
A semelhança do trabalho de Hiransha et al. (2018) com o trabalho aqui proposto é a comparação do desempenho de métodos diferentes de aprendizado de máquina a fim de comparar a precisão de cada método. Aqui também serão feitos testes com tamanhos distintos de janela e comparados os valores de erro após a validação dos modelos. 
A principal diferença é que o trabalho desenvolvido por Hiransha et al. (2018) treina apenas um modelo para cada tipo de rede neural utilizando o conjunto de dados histórico da TATA MOTORS e validando com dados de outras empresas, enquanto esse trabalho faz o treinamento e validação das redes neurais utilizando os dados da mesma empresa.

Estudo de predição do valor de ações utilizando variantes de RNR
Saud e Shakya (2020) apresentam em seu trabalho um estudo de predição de ações no setor bancário da bolsa de valores do Nepal utilizando variações de redes neurais recorrentes. As variações estudadas nesse trabalho são: VRNN, LSTM e GRU.
Utilizando dados históricos de 2007 até 2018, foram utilizados modelos com 6 camadas (uma camada de entrada, quatro intermediárias e uma de saída), com a camada de entrada composta por 14 neurônios, as intermediárias compostas por 50 neurônios cada, e a de saída composta por apenas um neurônio. Os conjuntos de dados são pré-processados antes do treinamento dos modelos, e o atributo a ser predito é o valor do fechamento do dia seguinte. Os atributos utilizados como entrada são: valor de abertura, fechamento, máximo, mínimo, volume negociado, valor total negociado, máximo-mínimo, abertura-fechamento, média móvel de 3 dias, média móvel de 10 dias, média móvel de 30 dias, desvio padrão, índice de força relativa e Williams' %R (SAUD; SHAKYA, 2020).
Os autores utilizam de diversos gráficos dos valores reais e preditos das ações do Nepal Investment Bank e Nabil Bank, comparando o erro mínimo obtido por cada modelo e utilizando 7 tamanhos diferentes da janela: 2, 5, 10, 15, 20, 25 e 30 dias. São feitos 10 experimentos para cada tamanho de janela, e o menor erro absoluto médio percentual obtido pra cada janela é comparado entre VRNN, LSTM e GRU.
Os tipos de redes neurais utilizadas nesse trabalho foram inspirados pelo artigo de Saud e Shakya (2020), mas a intenção deste é utilizar ações de empresas de áreas diferentes, não só do setor bancário, e fazer um teste mais aprofundado nos hiperparâmetros utilizados

Desenvolvimento
Este capítulo tem a finalidade de descrever como os hiperparâmetros dos modelos foram definidos. Para medir a acurácia de diferentes tipos de redes neurais recorrentes utilizando diferentes ações da Bolsa de Valores brasileira, foi implementado um modelo utilizando a linguagem de programação Python, com o framework Keras e com base na biblioteca para aprendizado de máquina Tensorflow.
O Python é uma linguagem de programação amplamente utilizada que permite abstração de dados e possui uma biblioteca padrão extensa (LUSZCZEK; DONGARRA, 2007). A linguagem ganha destaque pela facilidade de implementação e por um grande número de funcionalidades, dispondo de bibliotecas que auxiliam o programador no desenvolvimento de projetos de AM de qualquer tipo de finalidade, como Keras, Tensorflow e Scikit-learn.

Coleta de dados
Os dados do preço histórico das ações da Petrobras (PETR4), Grupo Fleury (FLRY3) e Vale (VALE3) foram coletadas do site Yahoo! Finance e baixadas no formato comma separated value (.csv) (YAHOO!. . . , 2020). O conjunto de dados extraído continha dados de 01 de janeiro de 2010 até 31 de dezembro de 2019, possuindo informações da data, valor de abertura, valor máximo, valor mínimo, valor de fechamento, valor de fechamento ajustado e volume.
Os dados presentes na Tabela 1 são descritos como:
• Date (Data): data do dia que ocorreram as transações.
• Open (Abertura): preço da ação durante a abertura do mercado, antes de iniciarem as negociações do dia.
• High (Máximo): valor mais alto que a ação atingiu durante as negociações no dia.
• Low (Mínimo): valor mais baixo que a ação atingiu durante as negociações no dia.
• Close (Fechamento): valor da ação no momento em que o horário de negociações do dia chegou ao fim.
• Adjusted Close (Fechamento Ajustado): valor de fechamento ajustado para incluir quaisquer distribuições de proventos e ações corporativas que ocorreram em qualquer momento antes da abertura do dia seguinte.
• Volume (Volume): número de ações negociadas durante o dia. O objetivo desse trabalho é fazer a predição dos valores de fechamento citados acima.

Tratamento de Dados
Antes de utilizar o conjunto de dados para treinamento dos modelos de redes neurais, é necessário fazer um pré-processamento com o objetivo de retirar do conjunto qualquer tipo de informação que possa atrapalhar o aprendizado das redes neurais, e adicionar informações relevantes que melhorem o desempenho dos modelos.
Primeiramente, são retiradas as linhas que contenham valores nulos (null) ou zeros para limpar informações irrelevantes do dataset (por exemplo, dias em que o volume de ações negociadas era 0, indicando possivelmente um feriado, o que não traria nenhuma informação relevante para o treinamento dos modelos). Em seguida, a coluna de data é excluída, e todo o conjunto de dados é normalizado para valores entre 0 e 1 através da função MinMaxScaler(). Essa normalização é importante pois aumenta a acurácia de vários modelos de aprendizado de máquina (JAMES et al., 2018), e é feita através da equação:
A Tabela 2 mostra a base de dados após essa normalização.
De acordo com o trabalho de Rui e Lee (2000), o volume negociado de uma certa ação não influencia diretamente em seu preço no futuro. Ao testar modelos treinados por uma base de dados com e sem a coluna de volume, foi possível observar ainda que o modelo que não utilizava a coluna de volume para fazer as predições obteve melhor resultado, e por isso essa informação não foi utilizada para os outros testes. Na seção 3.4 é mostrado o resultado que levou a essa escolha.
Para melhorar e facilitar o treinamento das redes neurais, foram adicionadas 3 medidas de Médias Móveis (MM): as MMs dos últimos 3, 10 e 30 dias (SAUD; SHAKYA, 2020). A MM é uma medida que pode ser utilizada para fazer predições simples dos valores de ações Lauren e Harlili (2014), consegue diminuir o erro resultante das predições com redes neurais artificiais.

Construção dos Modelos
Com os dados necessários para o aprendizado dos modelos já tratados, foram construídos o modelos de rede neural LSTM, VRNN e GRU em linguagem Python utilizando a interface de implementação para algoritmos de aprendizado de máquina TensorFlow (ABADI et al., 2015). A Application Programming Interface (API) de deep learning que é executada através do TensorFlow é chamada de Keras (CHOLLET et al., 2015).
Os modelos foram construídos utilizando os mesmos hiperparâmetros e número de camadas, e os parâmetros ótimos a serem utilizados foram definidos com o modelo LSTM servindo de teste. O conjunto de dados foi separado, sendo 90% utilizado para treinamento, e 10% utilizado para teste. A definição dos parâmetros ótimos é descrita detalhadamente na próxima seção.

Definição dos Hiperparâmetros
Hiperparâmetros são parâmetros cujos valores são utilizados para controlar o processo de aprendizado de redes neurais. Diferentemente dos parâmetros de peso dos neurônios, que é calculado através do treinamento dos modelos, os hiperparâmetros devem ser definidos pelo programador. Neste trabalho, foram feitos testes para valores diferentes dos parâmetros de número de camadas, número de neurônios de cada camada, porcentagem de dropout, otimizador, tamanho do lote e função de ativação.
Para o número de camadas das redes, foram feitos diferentes testes separadamente, e para os outros parâmetros, foi utilizado inicialmente o Tensorboard Abadi et al. (2015) para treinar 72 modelos com parâmetros diferentes a fim de encontrar um modelo que servisse de base, com o conjunto de dados da ação FLRY3 e número de épocas e tamanho da janela fixos.
A partir do modelo com o menor valor de erro dentre os treinados e analisados através do Tensorboard, foram feitos novos testes, dessa vez com o número de épocas maior, variando os hiperparâmetros um a um, e analisando os resultados de erro novamente. O modelo com menor erro absoluto médio observado no Tensorboard possuiu os seguintes valores: 256 neurônios para cada camada, 20% de dropout, otimizador Adam, lote de 64 amostras e função de ativação tanh.

Camadas das Redes Neurais
Ao construir os modelos, é necessário definir o número de camadas que os modelos irão utilizar. Não há uma definição exata para qual o número de camadas ou neurônios que um modelo deve ter para obter uma melhor performance, portanto esse tipo de parâmetro deve ser testado dependendo da finalidade do modelo e das características do conjunto de dados (STATHAKIS, 2009). Para esse trabalho, um modelo utilizando 4 camadas (1 de entrada, 2 intermediárias e 1 de saída) se mostrou mais preciso.

Número de Neurônios de Cada Camada
Cada camada de uma rede neural recorrente tem um número de neurônios. A camada de saída foi fixada em apenas 1 neurônio, e as outras 3 camadas tiveram seu número de neurônios variado entre 32, 64, 128 e 256 para cada uma das camadas.
Na Figura 9, podemos ver que os menores valores de EQM e EAM foram obtidos para camadas de 128 neurônios cada, portanto esse valor será utilizado como novo padrão para os outros testes.

Dropout
O dropout é um parâmetro importante pois reduz o chamado sobreajuste (do inglês overfitting), um tipo de erro de modelação que acontece quando o modelo se ajusta excessivamente ao conjunto de dados utilizado para o treinamento, de forma que o modelo perde a capacidade de generalização. Um modelo sobreajustado tem bons resultados para prever os valores do conjunto de testes, mas tem baixo desempenho para o conjunto de validação do modelo.
O fator de dropout escolhe aleatoriamente uma porcentagem das células dentro de cada camada do modelo e substitui o valor do output por 0 (SRIVASTAVA et al., 2014).
A Figura 10 ilustra os valores mínimos de dropout obtidos pelo modelo ao longo dos treinamentos. Pode-se perceber que o valor ótimo de dropout é 30% por ter menor EQM e EAM, portanto será esse o valor usado para o treinamento dos próximos modelos.

Otimizador
Otimizadores são algoritmos utilizados em redes neurais com o intuito de minimizar o erro, identificando os valores de peso ótimos a serem empregados na rede neural baseado nos dados de treinamento através do valor mínimo local da função. Os otimizadores mais comuns utilizados para RNRs são o Adam, o Stochastic Gradient Descent (SGD) e o RMSProp.
A Figura 11 mostra os valores mínimos de erro alcançados pelos otimizadores citados anteriormente. Apesar dos valores de erro mínimo apresentados pelos otimizadores Adam e RMSProp serem bem próximos, o Adam ainda obteve resultados melhores de EQM e EAM, tanto para os erros mínimos quanto levando em conta a média dos resultados de todos os testes realizados, e por isso continuará sendo usado para os testes.

Tamanho do Lote
O tamanho do lote é um termo utilizado em aprendizado de máquina para representar quantos dados de treinamento serão utilizados em uma iteração. Esse parâmetro define o número de amostras a serem apresentadas para o modelo antes do peso ser atualizado, ou seja, para um lote de tamanho 32, as primeiras 32 amostras (0-31) do conjunto de dados de treinamento serão tomadas e treinadas no modelo, em seguida as próximas 32 amostras (32-63) serão usadas para o treinamento, e assim por diante até chegar ao final das amostras.
Pode-se perceber pela Figura 12 que o modelo utilizando treinado com 16 amostras de dados de cada vez teve um melhor desempenho quando comparado aos outros, e por isso esse será o parâmetro utilizado para o treinamento dos próximos modelos.

Função de Ativação
Para redes neurais artificiais, a função de ativação é uma função não-linear que é aplicada à saída de um neurônio e ajuda a regular o vetor de peso que será passado aos próximos neurônios na rede. Para redes neurais recorrentes, as funções de ativação mais utilizadas são a sigmoide, a tangente hiperbólica (tanh) e a unidade linear retificada (ReLU, do inglês Rectified Linear Unit, e serão essas três as funções utilizadas para os testes.
Devido ao erro menor nos dois casos, mostrado na Figura 13, a função de ativação utilizada para o modelo será a tangente hiperbólica.

Número de Épocas
Uma época é uma iteração de quando conjunto de dados de treinamento inteiro é passado pela rede neural uma vez. Portanto, o número é épocas é considerado o número de passagens do conjunto de dados através da rede neural. É um parâmetro importante para se definir, pois quanto maior o número de épocas, mais o modelo se adapta ao conjunto de dados, e por isso deve ser escolhido com cautela. Se o número de épocas for muito pequeno, o modelo pode não se ajustar corretamente ao treinamento, causando valores altos de erros; se o número for muito grande, o modelo pode se ajustar excessivamente ao conjunto, causando sobreajuste.
Observando a Figura 14, temos o menor valor de erro para o modelo treinado com 500 épocas, e para maior número de épocas, esse valor para de diminuir. Apesar de parecer ser o número ótimo de épocas a ser tomado para o modelo, vejamos o erro obtido pelos modelos para a previsão, utilizando o conjunto de dados de teste na Figura 15:
Pelo segundo gráfico, vemos que o modelo que têm a melhor predição é na verdade o de 400 épocas, portanto, será aplicado nas etapas seguintes do trabalho.

Tamanho da Janela
O tamanho da janela (em inglês, window size, também chamado de look back period) é o número de dados que o modelo utilizará do conjunto para fazer a próxima previsão. Por exemplo, no contexto desse trabalho, para uma janela de tamanho 30, o modelo considerará os 30 últimos dias do conjunto para prever o valor da ação no dia seguinte.
Novamente, olhando para a Figura 16, o melhor parâmetro a ser escolhido parece ser a janela de tamanho 20, apesar de o tamanho 2 também possuir erro bastante baixo. Então, vamos novamente observar o erro quando o modelo é aplicado ao conjunto de teste na Figura 17:
Portanto, a partir da Figura 17, pode-se perceber que o valor menor de erro para os dados de teste é obtido quando a janela de aprendizado é de tamanho 2, e será o valor utilizado como parâmetro para os modelos de teste.

Resultados Obtidos
Como mencionado anteriormente, para obtenção dos resultados serão feitos testes de 4 ações da bolsa de valores: Grupo Fleury (FLRY3), Petrobras (PETR4) e Vale (VALE3); usando 3 modelos de RNR diferentes (VRNN, LSTM e GRU). Os gráficos resultantes dos testes serão apresentados a seguir de acordo com a ação. Os parâmetros utilizados para os modelos foram: 128 neurônios de cada camada intermediária e de entrada, dropout de 30%, otimizador Adam, lote de tamanho 16, função de ativação tanh, 400 épocas e janela de tamanho 2.
Como pode-se ver na Tabela 3, quando calculado o erro quadrático médio dos modelos, o VRNN tem o erro relativamente maior do que dos outros dois para todas as ações, enquanto o erro do GRU é ainda menor do que o do modelo LSTM, mas a diferença é pequena.
Comprovando o que foi visto na Tabela 3, a Tabela 4 mostra também como o modelo de rede neural recorrente mais simples é menos preciso na predição dos que os LSTM e GRU. Esses dois últimos modelos tiveram resultados bem parecidos para as ações PETR4 e VALE3, com o GRU obtendo valores menores de erro nos dois casos, enquanto para FLRY3, o modelo LSTM teve uma melhor predição com uma margem maior do que para outras ações. Isso pode ter acontecido devido ao fato de que os parâmetros foram otimizados usando essa última ação e o modelo LSTM.
No caso da ação FLRY3, a rede neural recorrente mais simples (Figura 18a) conseguiu identificar o padrão relativamente bem no começo, mas a partir da alta que essa ação teve no dia 100, não foi tão bem-sucedida quanto antes. A LSTM (Figura 18b) conseguiu identificar bem o padrão e teve bons resultados durante todo o treinamento, e a GRU (Figura 19) no começo teve um desempenho semelhante à LSTM mas, assim como a VRNN, não conseguiu identificar tão bem o padrão depois do dia 100.
Já para a ação PETR4, a VRNN (Figura 20a) consegue identificar bem o padrão, mas tem dificuldade para se ajustar mais precisamente aos valores reais entre os dias 0 e 50 e entre 100 e 200. Os modelos LSTM e GRU (Figura 20b e Figura 21, respectivamente) conseguiram se ajustar muito bem ao modelo, predizendo valores muito próximos aos reais. A GRU levou uma pequena vantagem com erros um pouco menores, o que dá pra ser visto principalmente perto do dia 210.
Finalmente, para a ação VALE3, o modelo VRNN conseguiu se encaixar melhor ao conjunto de teste, obtendo erros menores do que quando comparado às outras duas ações, mas ainda obtendo desempenho inferior ao do LSTM e GRU (respectivamente, Figura 22b e Figura 23). Como para a ação PETR4, os dois últimos modelos tiveram resultados semelhantes, com pequena vantagem do modelo GRU, que pode ser observada principalmente a partir do dia 150.

Trabalhos Futuros
Esse trabalho abordou a predição do valor de fechamento de ações da bolsa de valores com 3 tipos de redes neurais artificiais (LSTM, VRNN e GRU), onde os parâmetros dos modelos finais foram definidos através da otimização da LSTM. Em geral, a LSTM e a GRU tiveram melhor resultado, enquanto a VRNN não conseguiu prever os valores com tanta precisão.
Da forma como os modelos foram otimizados, foram usados os mesmos parâmetros para as três redes neurais recorrentes, o que pode ter beneficiado o resultado da LSTM, que foi utilizada para otimização dos parâmetros. Uma outra abordagem poderia ser otimizar todos os parâmetros para cada rede neural separadamente, o que provavelmente resultaria em parâmetros variados para cada modelo, e comparar novamente os resultados obtidos de cada uma das redes neurais. Nessa abordagem, provavelmente a VRNN e a GRU obteriam resultados mais precisos.
Além disso, outra forma de medir a precisão dos modelos poderia ser utilizada. Uma abordagem recorrente nos artigos encontrados nos últimos anos, principalmente no tema de algotrading, utiliza a predição da direção da variação do valor da ação para calcular a precisão. Nesse tipo de abordagem, é calculado a porcentagem do modelo que previu a movimentação correta da ação, ou seja, se o modelo previu que o valor de uma ação ia subir quando ele realmente subiu (sinal de compra da ação), ou abaixar quando ele realmente abaixou (sinal de venda da ação). Alguns trabalhos incluem mais um parâmetro a se analisar, que seria um sinal de hold, que é quando o valor da ação nem aumentou nem diminuiu, mas se manteve em uma margem definida, e por isso não deve ser nem comprada nem vendida de acordo com o modelo.
Mais uma forma de medir a precisão, também voltada para artigos focados em algotrading, é utilizar o modelo de predição juntamente com alguma estratégia de investimento e calcular o lucro que o modelo traria se a estratégia tivesse sido aplicada no período de teste.
Por fim, esse trabalho teve como objetivo o foco em redes neurais recorrentes, mas essa comparação pode ser feita também para modelos além desses, como para redes neurais convolucionais, perceptrons de múltiplas camadas, máquinas de vetores de suporte, entre várias outras. Como citado anteriormente nesse trabalho, também é válida a junção de múltiplos métodos em um modelo de previsão mais robusto, e também estão sendo desenvolvidas novas técnicas que podem aumentar a precisão dos modelos, como a avaliação de textos retirados da internet de analistas do mercado financeiro, que podem influenciar no preço de ações.

Conclusão
Este trabalho de conclusão de curso abordou o desafio de utilizar técnicas de redes neurais recorrentes para prever o valor de fechamento futuro de ações do mercado financeiro.
Para predizer o valor de três ações diferentes da bolsa de valores do Brasil (FLRY3, PETR4 e VALE3), foram utilizadas abordagens com três tipos redes neurais recorrentes para cada uma: a rede neural recorrente simples, também conhecida como Vanilla Recurrent Neural Network, a rede Long Short-Term Memory (LSTM), e a rede Gated Recurrent Unit (GRU). A acurácia de cada modelo foi medida através do cálculo do Erro Quadrático Médio (EQM) e do Erro Absoluto Médio (EAM).
A primeira abordagem, com o modelo VRNN, conseguiu captar os padrões em grande parte dos dados de teste, mas para nenhuma das ações teve um resultado tão bom quando comparado aos outros modelos. O valor de EQM obtido nos teste ficou em torno de 0,0009, e os valores de EAM ficaram acima de 0,019. 
A segunda abordagem proposta, com o modelo LSTM, obteve resultados muito bons, com valores de EQM e EAM perto de 0,00025 e 0,013 respectivamente, sendo que a acurácia foi um pouco menor para a ação VALE3. Foi o melhor modelo para a predição da ação FLRY3, mas teve o segundo melhor desempenho para as outras duas, com uma diferença bem pequena do melhor. Apesar disso, o desempenho melhor para a FLRY3 pode ser resultado da otimização dos parâmetros, pois o modelo e a ação em questão foram utilizados para definir os parâmetros para todos os modelos.
A terceira e última abordagem, com o modelo GRU, obteve o melhor resultado para duas ações (PETR4 e VALE3), e o segundo melhor para a terceira. o EQM desse modelo teve o menor valor de todos os testes (0,000239 com os dados de teste da PETR4), e também o menor valor de EAM (0,0117 para essa mesma ação).
Como o modelo GRU teve o melhor resultado em dois dos três casos, pode-se dizer que foi o modelo que obteve melhor desempenho, mas o LSTM teve um desempenho quase tão bom quanto. Já o modelo VRNN, apesar de conseguir identificar padrões, teve o pior resultado para esse tipo de predição, com diferenças grandes de erro para os outros dois.

